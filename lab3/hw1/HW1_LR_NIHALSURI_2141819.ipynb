{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\" and remove every line containing the expression: \"raise ...\" (if you leave such a line your code will not run).\n",
    "\n",
    "Do not remove any cell from the notebook you downloaded. You can add any number of cells (and remove them if not more necessary).\n",
    "\n",
    "Do not leave any variable initialized to None.\n",
    "\n",
    "## IMPORTANT: make sure to rerun all the code from the beginning to obtain the results for the final version of your notebook, since this is the way we will do it before evaluating your notebook!!!\n",
    "\n",
    "## Make sure to name your notebook file (.ipynb) correctly:\n",
    "### - HW1_LR_NAMESURNAME_ID (E.g. : HW1_LR_MARIOROSSI_2204567)\n",
    "\n",
    "## Fill in your name, surname and id number (numero matricola) below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"NIHAL SURI\"\n",
    "ID_number = int(\"2141819\")\n",
    "\n",
    "import IPython\n",
    "assert IPython.version_info[0] >= 3, \"Your version of IPython is too old, please update it.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d42ec8cf476d056efc5d0029d5a461f8",
     "grade": false,
     "grade_id": "cell-c5a538e1cbc4eaf5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Linear Regression  on a Combined Cycle Power Plant (CCPP) data\n",
    "\n",
    "\n",
    "## Dataset description\n",
    "\n",
    "The dataset contains 5281 data points collected from a Combined Cycle Power Plant over 6 years (2006-2011), when the power plant was set to work with full load. Features consist of hourly average ambient variables Temperature (T), Ambient Pressure (AP), Relative Humidity (RH) and Exhaust Vacuum (V) to predict the net hourly electrical energy output (EP)  of the plant.\n",
    "\n",
    "A combined cycle power plant (CCPP) is composed of gas turbines (GT), steam turbines (ST) and heat recovery steam generators. In a CCPP, the electricity is generated by gas and steam turbines, which are combined in one cycle, and is transferred from one turbine to another. While the Vacuum has effect on the Steam Turbine, the other three of the ambient variables effect the GT performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b9847c6d346d68cf2906b5cf20b92efd",
     "grade": false,
     "grade_id": "cell-726b6f7a9f28921b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import division  \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "12871e3e4f079b46ec80c144a413e08f",
     "grade": false,
     "grade_id": "cell-7cd0d97ab5e8c5af",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## Import Data\n",
    "# Load the data from a .csv file\n",
    "np.random.seed(ID_number)\n",
    "\n",
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/LucaZancato/ML2020-2021/main/ccpp_Data_clean2018.csv\"\n",
    "data = np.array(pd.read_csv(url, sep=';'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1433a5e59a686fe249212e1c4509d836",
     "grade": false,
     "grade_id": "cell-69c9c498ee4e90cd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# A quick overview of data\n",
    "\n",
    "In order to inspect the data you can use the method `describe()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "370ec6af7ac35c56d7cb3eb340ef9139",
     "grade": false,
     "grade_id": "cell-a4f9205e8f9c690c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "dataDescription = stats.describe(data)\n",
    "print(dataDescription) \n",
    "print(data.shape)\n",
    "# for more interesting visualization use Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas visualization \n",
    "df = pd.read_csv(url)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Split the column 'AT;V;AP;RH;PE' into multiple columns\n",
    "df[['AT', 'V', 'AP', 'RH', 'PE']] = df['AT;V;AP;RH;PE'].str.split(';', expand=True)\n",
    "\n",
    "# Step 3: Convert columns to numeric (if not automatically detected)\n",
    "df['AT'] = pd.to_numeric(df['AT'], errors='coerce')\n",
    "df['V'] = pd.to_numeric(df['V'], errors='coerce')\n",
    "df['AP'] = pd.to_numeric(df['AP'], errors='coerce')\n",
    "df['RH'] = pd.to_numeric(df['RH'], errors='coerce')\n",
    "df['PE'] = pd.to_numeric(df['PE'], errors='coerce')\n",
    "\n",
    "# Drop the original combined column\n",
    "df.drop(columns=['AT;V;AP;RH;PE'], inplace=True)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(df['AT'], bins=30, kde=True, color='orange')\n",
    "plt.title(\"Distribution of AT (Temperature)\")\n",
    "plt.xlabel(\"AT (Temperature)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x='AT', y='PE', data=df)\n",
    "plt.title(\"Scatter Plot of AT vs PE\")\n",
    "plt.xlabel(\"AT (Temperature)\")\n",
    "plt.ylabel(\"PE\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5addf1ecec02d1889196e5fe1e520db6",
     "grade": false,
     "grade_id": "cell-a8c8724a2a960222",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Split data in training, validation and test sets\n",
    "\n",
    "\n",
    "\n",
    "Given $m$ total data, keep $m_t$ data as training data, $m_{val}$ as validation data and $m_{test}:=m - m_{val} - m_t$. For instance one can take $m_t=m/3$ of the data as training, $m_{val}=m/3$  validation and $m_{test}=m/3$ as testing. Let us define\n",
    "\n",
    "$\\bullet$ $S_{t}$ the training data set\n",
    "\n",
    "$\\bullet$ $S_{val}$ the validation data set\n",
    "\n",
    "$\\bullet$ $S_{test}$ the testing data set\n",
    "\n",
    "\n",
    "The reason for this splitting is as follows:\n",
    "\n",
    "__TRAINING DATA__: The training data are used to compute the empirical loss\n",
    "$$\n",
    "L_S(h) = \\frac{1}{m_t} \\sum_{z_i \\in S_{t}} \\ell(h,z_i)\n",
    "$$\n",
    "which is used to estimate $\\hat{h}$ (ERM) in a given model class ${\\cal H}$, i.e.: \n",
    "$$\n",
    "\\hat{h} = {\\rm arg\\; min}_{h \\in {\\cal H}} \\, L_S(h)\n",
    "$$\n",
    "\n",
    "__VALIDATION DATA__: When different model classes are present (e.g. of different complexity, such as linear regression which uses a different number $d$ of regressors $x_1,\\dots,x_{d}$), one has to choose which one is the \"best\" complexity. \n",
    "Let ${\\cal H}_{d}$ be the space of models as a function of the complexity $d$ and let \n",
    "$$\n",
    "\\hat h_{d} = {\\rm arg\\; min}_{h \\in {\\cal H}_{d}} \\, L_S(h)\n",
    "$$\n",
    "\n",
    "One can estimate the generalization error for model $\\hat h_{d}$ as follows:\n",
    "$$\n",
    "L_{{\\cal D}}(\\hat h_{d}) \\simeq \\frac{1}{m_{val}} \\sum_{ z_i \\in S_{val}} \\ell(\\hat h_{d},z_i)\n",
    "$$\n",
    "and then choose the complexity which achieves the best estimate of the generalization error\n",
    "$$\n",
    "\\hat d: = {\\rm arg\\; min}_{d} \\,\\frac{1}{m_{val}} \\sum_{ z_i \\in S_{val}} \\ell(\\hat h_{d},z_i)\n",
    "$$\n",
    "\n",
    "__TESTING DATA__: Last, the test data set can be used to estimate the performance of the final estimated model\n",
    "$\\hat h_{\\hat d}$, using:\n",
    "$$\n",
    "L_{{\\cal D}}(\\hat h_{\\hat d}) \\simeq \\frac{1}{m_{test}} \\sum_{ z_i \\in S_{test}} \\ell(\\hat h_{\\hat d},z_i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3efde263c75347bc0d34da0527409ced",
     "grade": false,
     "grade_id": "cell-d22064ae51249482",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO 1\n",
    "# Write a function which takes as input a dataset and returns 3 datasets: S_t, S_val, S_test.\n",
    "# Each dataset is represented as a matrix m \\times d (numpy ndarray), where m is the number of data and d is the \n",
    "# number of features.\n",
    "def create_train_val_test_datasets(data : np.ndarray, m_t : int, m_val : int, m_test : int):\n",
    "    '''\n",
    "    Create training (S_t), validation (S_val) and test (S_test) sets starting from a dataset. \n",
    "    This function shuffles the complete dataset before creating the subsets. If you call this function twice it is \n",
    "    expected to get different S_t, S_val, S_test.\n",
    "    \n",
    "    :param data: NumPy ndarray containing all the data we can use\n",
    "    :param m_t: Number of samples for the training dataset\n",
    "    :param m_val: Number of samples for the validation dataset\n",
    "    :param m_test: Number of samples for the test dataset\n",
    "    \n",
    "    :returns: (S_t, S_val, S_test)\n",
    "    :rtype: tuple\n",
    "        WHERE\n",
    "        S_t : np.ndarray is the training dataset\n",
    "        S_val : np.ndarray is the validation dataset\n",
    "        S_test : np.ndarray is the test dataset\n",
    "    '''\n",
    "    # SUGGESTION: Use the function np.random.permutation (see the documentation) to create a permutation of the \n",
    "    #             dataset indexes. Then use these shuffled indexes to create S_t, S_val, S_test\n",
    "    # YOUR CODE HERE\n",
    "    permuted_data = np.random.permutation(data)\n",
    "    S_t = permuted_data[0 : m_t]\n",
    "    S_val = permuted_data[m_t : m_t + m_val]\n",
    "    S_test = permuted_data[m_t + m_val : ]\n",
    "    return S_t, S_val, S_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7609f5db54686632b603e48e9a343db2",
     "grade": false,
     "grade_id": "cell-537969ce72fcf2bb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's split the data in training, validation and test sets (as $m_t=m_{val} = \\lfloor\\frac{m}{3}\\rfloor$, $m_{test} = m-m_t-m_{val}$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "518ed555c3536c4c51668dadd6ebdccf",
     "grade": false,
     "grade_id": "cell-90646823b28ed6a3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Let's split the data into 3 datasets\n",
    "m = data.shape[0]\n",
    "m_t, m_val = m // 3, m // 3\n",
    "m_test = m - m_t - m_val\n",
    "S_t, S_val, S_test = create_train_val_test_datasets(data, m_t, m_val, m_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4fcc9173b8801d2574c629b421cf0f43",
     "grade": true,
     "grade_id": "cell-e60d833da7d1fb87",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert S_t.shape    == (m_t,    data.shape[1]) # here we are comparing two tuples (it is an element wise comparison)\n",
    "assert S_val.shape  == (m_val,  data.shape[1])\n",
    "assert S_test.shape == (m_test, data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1a074c30a4f099dec29e88b8d89f4631",
     "grade": false,
     "grade_id": "cell-72a0251b44efaf47",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Now we get input data (X) and output data (y, variable to be predicted) from S_t, S_val, S_test \n",
    "x_train, y_train = S_t[:,:-1],    S_t[:,-1].reshape(-1,1) # We use reshape so that we will get a column vector\n",
    "x_val,   y_val   = S_val[:,:-1],  S_val[:,-1].reshape(-1,1)\n",
    "x_test,  y_test  = S_test[:,:-1], S_test[:,-1].reshape(-1,1)\n",
    "print(f\"Training input data size:    {x_train.shape}\")\n",
    "print(f\"Training output data size:   {y_train.shape}\")\n",
    "print(f\"Validation input data size:  {x_val.shape}\")\n",
    "print(f\"Validation output data size: {y_val.shape}\")\n",
    "print(f\"Test input data size:        {x_test.shape}\")\n",
    "print(f\"Test output data size:       {y_test.shape}\")\n",
    "# Let's get the number of features\n",
    "d = x_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "07e9e60de038252d576727f7b6eaf515",
     "grade": false,
     "grade_id": "cell-45882ea55b4fc69a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Data Normalization\n",
    "\n",
    "It is common practice in Statistics and Machine Learning to scale the data (= each variable) so that it is centered (zero mean) and has standard deviation equal to 1. This helps in terms of numerical conditioning for the (inverse) problems of estimating the model (the coefficients of the linear regression in this case), as well as to give the same scale to all the coefficients. \n",
    "\n",
    "NOTE: Data normalization is achieved by means of a preprocessing function: the scaler. \n",
    "If you want to normalize your data to have zero (empirical) mean and unit (empirical) variance the scaler will simply be a function that takes each data point, remove the empirical mean and then divide the result by the empirical variance. In this way you get a new normalized dataset. \n",
    "\n",
    "NORMALIZATION and TRAINING PROCEDURE:\n",
    "\n",
    "1. You are given a training dataset, you need to find the proper scaler in order to preprocess it (e.g. use empirical mean and variance, if you want to apply the normalization by mean and variance, you could also use a different normalization for example based on the max and min) \n",
    "\n",
    "\n",
    "2. Apply the scaler to get the preprocessed training dataset \n",
    "\n",
    "\n",
    "3. Fit a model in your preferred class on the normalized dataset\n",
    "\n",
    "\n",
    "4. Now you need to test your trained model on new data in order to get an estimate of the generalization error. Note that you have trained your model using normalized data, this means that the model expects data that have been normalized (according to the same preprocessing step as the training data). This means that you need to apply the same scaler (that exploits the empirical mean and variance computed from the training dataset) to the test dataset (the same holds true for the validation dataset).\n",
    "\n",
    "See next cell (note that the mean and std for the validation and test sets are not 0 and 1 respectively!)\n",
    "\n",
    "__Remark__: Both input x and output y can be normalized!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f9a7cf5a6f5d2250d0492867494f36b4",
     "grade": false,
     "grade_id": "cell-4dff8834c63ae2c7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Let's standardize our data: in this case we only standardize input data X\n",
    "from sklearn import preprocessing\n",
    "# Find the right scaler (we are allowed to use only training data in this step)\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "print(f\"Mean of the training input data:   {x_train.mean(axis=0)}\")\n",
    "print(f\"Std of the training input data:    {x_train.std(axis=0)}\")\n",
    "# Apply the tranformation we got with the training dataset both to the validation and test ones\n",
    "x_val = scaler.transform(x_val) # use the same transformation on validation data\n",
    "print(f\"Mean of the validation input data: {x_val.mean(axis=0)}\")\n",
    "print(f\"Std of the validation input data:  {x_val.std(axis=0)}\")\n",
    "x_test = scaler.transform(x_test) # use the same transformation on test data\n",
    "print(f\"Mean of the test input data:       {x_test.mean(axis=0)}\")\n",
    "print(f\"Std of the test input data:        {x_test.std(axis=0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "52bff3ff5c6032a0ad604463f772b526",
     "grade": false,
     "grade_id": "cell-c0ac76a9a1782ae5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Let's wrap the code above in single function since we will need it many times\n",
    "def data_preprocessing(train_data : np.ndarray, val_data : np.ndarray, test_data : np.ndarray, scaler): \n",
    "    '''\n",
    "    Function used to scale data (train, validation, test) using a tranformation based on training data. \n",
    "    This function returns also the fitted scaler, since we will need it in order to transform other future data.\n",
    "    \n",
    "    :param train_data: NumPy ndarray containing the train data we can use\n",
    "    :param val_data: NumPy ndarray containing the validation data\n",
    "    :param test_data: NumPy ndarray containing the test data\n",
    "    :param scaler: Scaler from sklearn.preprocessing\n",
    "    \n",
    "    :returns:  (scaled_train_data, scaled_val_data, scaled_test_data, fitted_scaler)\n",
    "    :rtype: tuple\n",
    "        WHERE\n",
    "        scaled_train_data: np.ndarray scaled train data\n",
    "        scaled_val_data: np.ndarray scaled validation data\n",
    "        scaled_test_data: np.ndarray scaled test data\n",
    "        fitted_scaler: fitted scaler\n",
    "    '''\n",
    "    fitted_scaler = scaler.fit(train_data)\n",
    "    return (fitted_scaler.transform(train_data), fitted_scaler.transform(val_data), \n",
    "            fitted_scaler.transform(test_data), fitted_scaler)\n",
    "\n",
    "# Let's normalize also the output data\n",
    "y_train, y_val, y_test, y_fitted_scaler = data_preprocessing(train_data=y_train, val_data=y_val, test_data=y_test, \n",
    "                                                             scaler=preprocessing.StandardScaler())\n",
    "print(f\"Mean of the training output data:   {y_train.mean(axis=0)}\")\n",
    "print(f\"Std of the training output data:    {y_train.std(axis=0)}\")\n",
    "print(f\"Mean of the validation output data: {y_val.mean(axis=0)}\")\n",
    "print(f\"Std of the validation output data:  {y_val.std(axis=0)}\")\n",
    "print(f\"Mean of the test output data:       {y_test.mean(axis=0)}\")\n",
    "print(f\"Std of the test output data:        {y_test.std(axis=0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5919e5e33f28bbc995c66df5d53f20cc",
     "grade": false,
     "grade_id": "cell-4324c7bf70816573",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def data_splitting_and_preprocessing(data : np.ndarray, m_t : int, m_val : int, m_test : int, \n",
    "                                     input_scaler, output_scaler):\n",
    "    '''\n",
    "    Perform in a single call all the preprocessing we have done so far!\n",
    "    \n",
    "    :param data: NumPy ndarray containing all the data we can use\n",
    "    :param m_t: Number of samples for the training dataset\n",
    "    :param m_val: Number of samples for the validation dataset\n",
    "    :param m_test: Number of samples for the test dataset\n",
    "    :param input_scaler: Scaler from sklearn.preprocessing to be applied to the inputs\n",
    "    :param output_scaler: Scaler from sklearn.preprocessing to be applied to the outputs\n",
    "    \n",
    "    :returns: (x_train, y_train, x_val, y_val, x_test, y_test, fitted_I_scaler, fitted_O_scaler)\n",
    "    :rtype: tuple\n",
    "        WHERE\n",
    "        x_train : np.ndarray is the scaled input training dataset\n",
    "        y_train : np.ndarray is the scaled output training dataset\n",
    "        x_val : np.ndarray is the scaled input validation dataset\n",
    "        y_val : np.ndarray is the scaled output validation dataset\n",
    "        x_test : np.ndarray is the scaled input test dataset\n",
    "        y_test : np.ndarray is the scaled output test dataset\n",
    "        fitted_I_scaler : fitted scaler to the inputs\n",
    "        fitted_O_scaler : fitted scaler to the outputs\n",
    "    '''\n",
    "    # Create training, validation, test datasets\n",
    "    S_t, S_val, S_test = create_train_val_test_datasets(data=data, m_t=m_t, m_val=m_val, m_test=m_test)\n",
    "    # Split datasets in input (x) and output (y)\n",
    "    x_train, y_train = S_t[:,:-1],    S_t[:,-1].reshape(-1,1)\n",
    "    x_val,   y_val   = S_val[:,:-1],  S_val[:,-1].reshape(-1,1)\n",
    "    x_test,  y_test  = S_test[:,:-1], S_test[:,-1].reshape(-1,1)\n",
    "    # Normalize input data (using a transformation based only on the training input data)\n",
    "    x_train, x_val, x_test, fitted_I_scaler = data_preprocessing(train_data=x_train, val_data=x_val, test_data=x_test, \n",
    "                                                                 scaler=input_scaler)\n",
    "    y_train, y_val, y_test, fitted_O_scaler = data_preprocessing(train_data=y_train, val_data=y_val, test_data=y_test, \n",
    "                                                                 scaler=output_scaler)\n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test, fitted_I_scaler, fitted_O_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so now x_train and y_train have 0 mean and 1 std and the same scaler has been applied to the "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "12f6854122d8d825dbc039ac733cb883",
     "grade": false,
     "grade_id": "cell-f4268da8d84ba50c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Model Training \n",
    "\n",
    "The model is trained (= estimated) minimizing the empirical error\n",
    "$$\n",
    "L_S(h) := \\frac{1}{m_t} \\sum_{z_i \\in S_{t}} \\ell(h,z_i)\n",
    "$$\n",
    "When the loss function is the quadratic loss\n",
    "$$\n",
    "\\ell(h,z) := (y - h(x))^2\n",
    "$$\n",
    "we define  the Residual Sum of Squares (RSS) as\n",
    "$$\n",
    "RSS(h):= \\sum_{z_i \\in S_{t}} \\ell(h,z_i) = \\sum_{z_i \\in S_{t}} (y_i - h(x_i))^2\n",
    "$$ so that the training error becomes\n",
    "$$\n",
    "L_S(h) = \\frac{RSS(h)}{m_t}\n",
    "$$\n",
    "\n",
    "We recall that, for linear models with scalar output we have $h(x) = <w,x>$ and the Empirical error $L_S(h)$ can be written\n",
    "in terms of the vector of parameters $w$ in the form\n",
    "$$\n",
    "L_S(w) = \\frac{1}{m_t} \\|Y - X w\\|^2\n",
    "$$\n",
    "where $Y$ and $X$ are the matrices whose $i-$th row are, respectively, the output data $y_i$ and the input vectors $x_i^\\top$.\n",
    "\n",
    "The least squares solution is given by the expression\n",
    "$$\n",
    "\\hat w = {\\rm arg\\;min}_w L_S(w) = (X^\\top X)^{-1} X^\\top Y\n",
    "$$\n",
    "When the matrix $X^\\top X$ is not invertible, the solution can be computed using the Moore-Penrose pseudoinverse $(X^\\top X)^{\\dagger}$ of $(X^\\top X)$\n",
    "$$\n",
    "\\hat w = (X^\\top X)^{\\dagger} X^\\top Y\n",
    "$$\n",
    "The Moore-Penrose pseudoinverse $A^\\dagger$ of a matrix $A \\in \\mathbb{R}^{m\\times n}$ can be expressed in terms of the Singular Value Decomposition (SVD) as follows:\n",
    "\n",
    "Let $A\\in \\mathbb{R}^{m\\times n}$ be of rank $r\\leq {\\rm min}(n,m)$ and let  \n",
    "$$\n",
    " A = USV^\\top\n",
    " $$\n",
    " be the singular value decomposition of  $A$ where  \n",
    " $$\n",
    " S = {\\rm diag}\\{s_1,s_2,..,s_r\\}\n",
    " $$\n",
    " Then \n",
    " $$\n",
    " A^\\dagger =V S^{-1} U^\\top \n",
    " $$\n",
    " \n",
    " In practice some of the singular values may be very small (e.g. $<1e-12$). Therefore it makes sense to \n",
    " first approximate the matrix $A$ truncating the SVD and then using the pseudoinverse formula.\n",
    " \n",
    " More specifically, let us postulate that, given a threshold $T_h$ (e.g $=1e-12$), we have $\\sigma_i<T_h$, for $i=\\hat r + 1,..,r$. Then we can approximate (by SVD truncation) $A$ using:\n",
    " \n",
    " $$A = USV^\\top =U \\,{\\rm diag}\\{s_1,s_2,..,s_r\\}\\, V^\\top \\simeq \\hat A_r = U\\,{\\rm diag}\\{s_1,s_2,..,s_{\\hat r}, 0,..,0\\}\\,V^\\top\n",
    " $$\n",
    " So that \n",
    " $$\n",
    " A^\\dagger \\simeq \\hat A_r^\\dagger:= V \\,{\\rm diag}\\{1/s_1,1/s_2,..,1/s_{\\hat r}, 0,..,0\\}\\, U^\\top\n",
    " $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0eb243896c3e2f35d114efd79e1fd964",
     "grade": false,
     "grade_id": "cell-f89dae087739e0c9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Pseudoinverse and Singular Value Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dd790fc15d35ff75014554f192778b62",
     "grade": false,
     "grade_id": "cell-c5c967d138604d0a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO 2\n",
    "# Create a function to compute the pseudo-inverse (as showed in the previous cell) of a general rectangular matrix \n",
    "def pseudoinverse(A : np.ndarray, threshold : float=1e-10) -> np.ndarray:\n",
    "    '''\n",
    "    Function to compute the pseudo-inverse of a general rectangular matrix.\n",
    "    \n",
    "    :param A: Matrix to be inverted\n",
    "    :param threshold: value under which we approximate the singular values with 0\n",
    "    :returns: Pseudo-inverse of A\n",
    "    :rtype: np.ndarray (this line could be avoided since it is present in the function definition)\n",
    "    '''\n",
    "    # SUGGESTIONS: \n",
    "    # 1- Use np.linalg.svd to get the SVD (be careful on the argument full_matrices)\n",
    "    # 2- Have a look at np.where to perform the threshold and inverse of S\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    # first lets calculate the general SVD of A: \n",
    "    U, S, V_transpose = np.linalg.svd(A, full_matrices=False)\n",
    "    # all singular values lesser than the threshold are approximated to 0\n",
    "    np.where(S < threshold, S, -0)\n",
    "    # print(np.diag(S))\n",
    "    # calculation of S_inverse \n",
    "    S_inverse = np.linalg.inv(np.diag(S))\n",
    "    # print(S_inverse)\n",
    "    # calculation of A_pseudo_inverse\n",
    "    A_pseudo_inverse = np.matmul(V_transpose.T , np.matmul (S_inverse, U.T))\n",
    "\n",
    "    return A_pseudo_inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check pseudoinverse function, remove cell before submission\n",
    "rng = np.random.default_rng()\n",
    "a = rng.normal(size=(3, 4)) + 1j*rng.normal(size=(3, 4))\n",
    "b = rng.normal(size=(2, 7, 8, 3)) + 1j*rng.normal(size=(2, 7, 8, 3))\n",
    "\n",
    "U, S, Vh = np.linalg.svd(a)\n",
    "\n",
    "# print(U.shape)\n",
    "# print(S.shape)\n",
    "# print(Vh.shape)\n",
    "print(np.real(pseudoinverse(a)))\n",
    "print(np.real(np.linalg.pinv(a)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2b1e1f1b427c4c9e4394c0b1486e5a7b",
     "grade": true,
     "grade_id": "cell-d0191c60921b6d0b",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "A, B, C = np.random.normal(size=(4,4)), np.random.normal(size=(3,5)), np.random.normal(size=(5,3))\n",
    "assert np.isclose(np.abs(np.matmul(A, pseudoinverse(A)) - np.eye(A.shape[0])).sum(), 0., atol=1e-5)\n",
    "assert np.isclose(np.abs(np.matmul(B, pseudoinverse(B)) - np.eye(B.shape[0])).sum(), 0., atol=1e-5)\n",
    "assert np.isclose(np.abs(np.matmul(pseudoinverse(C), C) - np.eye(C.shape[1])).sum(), 0., atol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's go back to the original problem and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2a11e3ee3fb8aa82c71b25971047661c",
     "grade": false,
     "grade_id": "cell-58e5e9e1968b7ae0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Let's add a 1 in front of each sample data in order to describe also the bias term b through the \n",
    "# coefficients of the model w_hat!\n",
    "# From now on we will always assume w_hat contains this additional value!\n",
    "# Do not run this cell multiple times otherwise you will continue adding ones... \n",
    "# (we add the assert to avoid such issue)\n",
    "\n",
    "assert x_train.shape[1] == d\n",
    "assert x_test.shape[1] == d \n",
    "assert x_val.shape[1] == d \n",
    "\n",
    "x_train = np.hstack((np.ones((x_train.shape[0],1)), x_train))\n",
    "x_test  = np.hstack((np.ones((x_test.shape[0],1)),  x_test))\n",
    "x_val  = np.hstack((np.ones((x_val.shape[0],1)),  x_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "33d79eeeb4448c60a655acdfe018a835",
     "grade": false,
     "grade_id": "cell-f6c1e0f456f6dd0f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO 3\n",
    "# Write a function which computes the optimal parameters w_hat, solution to the LS problem described earlier.\n",
    "# We assume w_hat contains the bias term b (as described in class).\n",
    "def compute_LS_optimal_ERM_coefficients(x_train : np.ndarray, y_train : np.ndarray) -> np.ndarray:\n",
    "    '''\n",
    "    This function estimates the optimal LS coefficients given the input and output training data x, y. \n",
    "    This function assumes the bias term b is condensed with the other coefficients, therefore a column of ones must be \n",
    "    stacked to the input features and the size of the returned optimal coefficient is: number of features + 1\n",
    "    \n",
    "    :param x_train: input features \n",
    "    :param y_train: output to be predicted (it is assumed to be a single column vector, scalar output prediction case)\n",
    "    :returns: a column vector containing w_hat, solution to the ERM LS problem    \n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError() # Remove this line\n",
    "    return w_hat\n",
    "\n",
    "w_hat = compute_LS_optimal_ERM_coefficients(x_train, y_train)\n",
    "print(f\"w_hat \\n {w_hat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d77aef64d5507b73278efe23faa27aad",
     "grade": true,
     "grade_id": "cell-e00eab88210dabaf",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert w_hat.shape == (x_train.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "731854b056278f7915c2cca1f7a2c40f",
     "grade": false,
     "grade_id": "cell-bb8bbac056732c25",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO 4\n",
    "# Use the numpy least squares solver to find the optimal parameter w_hat (have a look at np.linalg.lstsq), we expect\n",
    "# w_hat to include the bias term b.\n",
    "\n",
    "w_hat_np = 0 # assign to this variable the proper output of the numpy LS solver\n",
    "rss_np = 0 # assign to this variable the residuals sum of squares returned by numpy LS solver\n",
    "\n",
    "# Suggestion: set the 'rcond' argument to None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError() # Remove this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae252837932694eb509af44fcec9da24",
     "grade": true,
     "grade_id": "cell-2bcd8dd1cf788e5c",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert w_hat_np.shape == (x_train.shape[1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b728aee18ec39eb6c6bb00fa56e65f45",
     "grade": false,
     "grade_id": "cell-c42daf7c68ccdd19",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Data prediction \n",
    "\n",
    "Compute the output predictions on both training and test set and compute the Residual Sum of Squares (RSS) defined above, the Empirical Loss and the quantity $R^2$ where\n",
    "$$\n",
    "R^2 = 1 - \\frac{\\sum_{z_i \\in S_t} (  y_i -  \\hat y_i (x_i))^2}{\\sum_{z_i \\in S_t} (y_i - \\bar y)^2} \\quad \\quad \\bar y = \\frac{1}{m_t} \\sum_{z_i \\in S_t} y_i\n",
    "$$\n",
    "$R^2$ is the so-called \"Coefficient of determination\" (COD).\n",
    "\n",
    "__Note__: The above COD is computed on the training dataset, the formula for the test dataset is similar (mutatis mutandis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "de4718252697c60de023432973595b35",
     "grade": false,
     "grade_id": "cell-e68ff64b7deb77f4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO 5\n",
    "# Let's assess model performance. \n",
    "# We are going to start with training error (both for our implementation and the numpy one)\n",
    "# And then we will evaluate test error \n",
    "# For now we will not use the validation dataset (it is usually used to choose the optimal hyper-parameters)\n",
    "\n",
    "def linear_predictions(w_hat : np.ndarray, x_data : np.ndarray) -> np.ndarray:\n",
    "    '''\n",
    "    Function used to compute the predictions of our linear model on a general input dataset (N times d), where N \n",
    "    is the number of data and d the number of features. Recall w_hat is a d + 1 dimensional vector, therefore we need\n",
    "    to check weather the dataset we pass has already been modified to take into account for the bias b!\n",
    "    If this is not the case, we must properly pre-process the data, adding 1 in the first position!\n",
    "    You should take this into account in your code!\n",
    "    Suggestion: place an if statement at the beginning to handle the case in which data do not have the correct\n",
    "    dimensions and to make them right, so you can proceed in both cases with the same code\n",
    "    \n",
    "    :param w_hat: Column vector (of dimension d + 1) composed by the coefficients of a linear model\n",
    "    :param x_data: input data used to get the linear model predictions\n",
    "    :returns: predictions of the linear model parametrized by w_hat\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError() # Remove this line\n",
    "    return predictions\n",
    "\n",
    "def rss(target_output : np.ndarray, model_output : np.ndarray) -> np.float64:\n",
    "    '''\n",
    "    Compute the residual sum of squares given two vectors: target outputs and model predictions\n",
    "    \n",
    "    :parameter target_output: column vector containing output we are willing to approximate\n",
    "    :parameter model_output: column vector containing model predictions\n",
    "    :return: residual sum of squares\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError() # Remove this line\n",
    "    return rss \n",
    "\n",
    "def cod(target_output : np.ndarray, model_output : np.ndarray) -> np.float64:\n",
    "    '''\n",
    "    Compute the coefficient of determination (COD) given two vectors: target outputs and model predictions\n",
    "    \n",
    "    :parameter target_output: column vector containing output we are willing to approximate\n",
    "    :parameter model_output: column vector containing model predictions\n",
    "    :return: COD\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError() # Remove this line\n",
    "    return cod\n",
    "\n",
    "# Evaluate RSS, COD and empirical LS loss on the training dataset\n",
    "predictions_train = 0                 # Replace with the proper values\n",
    "rss_hand_train, cod_hand_train = 0, 0 # Replace with the proper values\n",
    "ls_loss_hand_train = 0                # Replace with the proper value\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError() # Remove this line\n",
    "print(f\"rss on train dataset from numpy: {rss_np[0]:.4f}\")\n",
    "print(f\"Metrics on train dataset: rss={rss_hand_train:.4f}, cod={cod_hand_train:.4f}, loss={ls_loss_hand_train:.4f}\")\n",
    "\n",
    "# Evaluate RSS, COD and empirical LS loss on the test dataset\n",
    "predictions_test = 0                # Replace with the proper values\n",
    "rss_hand_test, cod_hand_test = 0, 0 # Replace with the proper values\n",
    "ls_loss_hand_test = 0               # Replace with the proper value\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError() # Remove this line\n",
    "print(f\"Metrics on test  dataset: rss={rss_hand_test:.4f}, cod={cod_hand_test:.4f}, loss={ls_loss_hand_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6b3bc374e50d10253e427493d528cb03",
     "grade": true,
     "grade_id": "cell-e6f942146c8dbc6d",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert predictions_train.shape[0] == x_train.shape[0]\n",
    "assert predictions_test.shape[0] == x_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8a7e6b07888dd27df56b4ff5aaf57329",
     "grade": false,
     "grade_id": "cell-08e7dc701a308669",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# plot predictions and histograms of errors (show the model has uniform errors)\n",
    "def plot_model_prediction_error(target_output : np.ndarray, model_output : np.ndarray, ax, plt_info : dict):\n",
    "    ax.plot(target_output-model_output, 'ko', alpha=0.5)\n",
    "    ax.set_xlabel('Input (index of instance)')\n",
    "    ax.set_ylabel('Prediction error')\n",
    "    ax.set_title(plt_info['title'])\n",
    "    ax.set_ylim([-3, 1.5])\n",
    "\n",
    "def plot_error_distributions(target_output : np.ndarray, model_output : np.ndarray, ax, plt_info : dict):\n",
    "    errors = target_output - model_output\n",
    "    label = f\"{plt_info['dataset']} dataset, mean: {errors.mean():.3f}, std: {errors.std():.3f}\"\n",
    "    ax.hist(errors, bins='auto', alpha=0.5, label=label)\n",
    "    ax.set_xlabel('Errors')\n",
    "    ax.set_ylabel('Errors count')\n",
    "\n",
    "# Plot model predictions vs true outputs\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10,5))\n",
    "plot_model_prediction_error(y_train, predictions_train, axes[0], {'title': 'Training Data'})\n",
    "plot_model_prediction_error(y_test, predictions_test, axes[1], {'title':'Test Data'})\n",
    "\n",
    "# Plot error distributions\n",
    "fig, axes = plt.subplots(1, 1, figsize=(10,5))\n",
    "plot_error_distributions(y_train, predictions_train, axes, {'dataset': 'Train'})\n",
    "plot_error_distributions(y_test, predictions_test, axes, {'dataset': 'Test'})\n",
    "axes.legend(), axes.set_title('Error Distributions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ab7780fef90a4dfb441a0f19aea17569",
     "grade": false,
     "grade_id": "cell-2738b82c819c6704",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**TO DO 6**: Answer in the next cell (you do not need more than 5-7 lines):\n",
    "\n",
    "1- What is the intuition behind the definition of COD, would you prefer it high or low?\n",
    "\n",
    "2- Looking at the plots above, do you think the learning algorithm found a good value for $\\hat w$? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d255cb35c78b74fdf92c251a752d9f2e",
     "grade": true,
     "grade_id": "cell-c3f139d320c78dfe",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7b46286b4e9653b8eb7a2c41dda9f699",
     "grade": false,
     "grade_id": "cell-17dc90de0b8d20fd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Confidence intervals for output predictions\n",
    "In the following we will use $d$ to represent the number of parameters of the linear model (which may contain the bias $b$).\n",
    "\n",
    "Having estimated the extended set of coefficients $\\hat w$ (remember this is the outcome of a random variable), and given a new location $x_0$, the output prediction  has the form\n",
    "$$\n",
    "\\hat y_0 : = x_0 ^\\top \\hat w .\n",
    "$$\n",
    "We assume that $X^T X$ is invertible and that \n",
    "$$\n",
    "y_0 = x_0^\\top w + \\epsilon_0 \\quad \\epsilon_0 \\sim {\\cal N}(0,\\sigma^2)\n",
    "$$\n",
    "where $w := \\mathbb{E}[\\hat{w}]$ (due to the invertibility assumption). You can think the last assumption is not that far from being true: remember the bell shaped errors we plotted before (very very close to be a gaussian)! We would like to compute a confidence interval on the output prediction or equivalently for the estimation error\n",
    "$$\n",
    "\\tilde y_0:=\\hat y_0 - y_0$$\n",
    "Using the equations above we have that \n",
    "$$\n",
    "\\tilde y_0 =x_0^\\top (\\hat w - w) -  \\epsilon_0\n",
    "$$\n",
    "where $\\epsilon_0$ and $\\hat w$ are uncorrelated (since $x_0$ is a new input location $\\hat{w}$ does not depend on $x_0$). It thus follows that ($x_0$ is a deterministic quantity)\n",
    "$$\n",
    "\\tilde y_0 \\sim {\\cal N}(0, x_0^\\top {Var}\\{\\hat w\\}x_0  + \\sigma^2)\n",
    "$$\n",
    "where\n",
    "$$\n",
    "x_0^\\top {Var}\\{\\hat w\\}x_0 = \\sigma^2 x_0^T (X^TX)^{-1}x_0 \\quad \\quad\n",
    "$$\n",
    "Try to compute the variance of the random variable $\\hat w$ (write its equation and then substitute $Y = Xw + E$ with $E\\sim \\mathcal N (0, \\sigma^2 I)$).\n",
    "\n",
    "__Note__: We do not know $\\sigma^2$, we must estimate it from the data!\n",
    "\n",
    "Using the results we have seen in class (extended to the case of unknown variance) we have that the interval \n",
    "$$\n",
    "[ - \\Delta_0, + \\Delta_0] \\quad \\quad \\Delta_0 : = \\hat\\sigma \\, t_{1-\\frac{\\alpha}{2}}(m_{t}-d-1) \\sqrt{x_0^\\top (X^\\top X)^{-1}x_0 + 1} \n",
    "$$\n",
    "where \n",
    "$$\n",
    "t_{1-\\frac{\\alpha}{2}}(m_{t}-d-1)\n",
    "$$\n",
    "is the $1-\\frac{\\alpha}{2}$ percentile of the Student's t-distribution, and\n",
    "$$\n",
    "\\hat\\sigma^2:= \\frac{1}{m_t-d-1}\\sum_{i\\in S_t} (y_i - \\hat w^\\top x_i)^2.\n",
    "$$\n",
    "The interval $[ - \\Delta_0, + \\Delta_0]$ satisfies the condition\n",
    "$$\n",
    "\\mathbb{P}[\\tilde y_0 \\in [ - \\Delta_0, + \\Delta_0]] =\\mathbb{P}[(\\hat  y_0 - y_0) \\in [ - \\Delta_0, + \\Delta_0]]= 1-\\alpha\n",
    "$$\n",
    "\n",
    "Note that the probability is to be understood with repect to both the choice of the traning set $(Y,X)$  as well as on the choice of $y_0$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "deb5eae336097add8fd4dbf5f87a63cc",
     "grade": false,
     "grade_id": "cell-3f59643d4c420c18",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO7: Compute confidence intervals [-delta_0,+delta_0] of the linear model on the test dataset, i.e. with x_0 above\n",
    "# taking values in x_test\n",
    "\n",
    "# Get t_percentile from scipy.stats, check the documentation\n",
    "from scipy.stats import t\n",
    "alpha = 0.05\n",
    "t_percentile = 0 # replace with the correct value of the percentile\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError() # Remove this line\n",
    "\n",
    "# Estimate sigma_2_hat\n",
    "sigma_2_hat = 0 # replace with the correct value of the estimate\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError() # Remove this line\n",
    "\n",
    "# In this case X^TX is invertible, therefore the pseudoinverse and the inverse are exactly the same.\n",
    "# Do not forget to add the column of ones to the dataset you are going to use but do not overwrite them! \n",
    "# Use the variable ci_O to save the output confidence intervals\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError() # Remove this line\n",
    "print(f\"These are the output confidence intervals \\n {ci_O} \\n of shape {ci_O.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4cf3089e8a225a2403bd55ef853134c6",
     "grade": true,
     "grade_id": "cell-e7962877dbe0239a",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert x_train.shape[1] == w_hat.shape[0]\n",
    "assert x_test.shape[1] == w_hat.shape[0]\n",
    "assert ci_O.shape[0] == x_test.shape[0]\n",
    "assert ci_O.shape[1] == 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "13c5ddd2acc2018eac32c35ee625d64d",
     "grade": false,
     "grade_id": "cell-3eea03e494939bca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_model_predictions_error_vs_CI(target_output : np.ndarray, model_output : np.ndarray, c_i : np.ndarray, ax, \n",
    "                                 plt_info : dict):\n",
    "    ax.plot(model_output-target_output, 'ko', alpha=0.5)\n",
    "    ax.fill_between(range(model_output.shape[0]),c_i[:,0], c_i[:,1], alpha=0.4)\n",
    "\n",
    "    ax.set_xlabel('Input (index of instance)')\n",
    "    ax.set_ylabel('Predicted Error')\n",
    "    ax.set_title(plt_info['title'])\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,5))\n",
    "plot_model_predictions_error_vs_CI(y_test, predictions_test, ci_O, ax, {'title': 'Confidence intervals on Test Data'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9d9a8164c57fc208059f19d2fbc0e1f3",
     "grade": false,
     "grade_id": "cell-22f7094302f99801",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Why do we need the validation dataset? \n",
    "Up to now we have not used it! But up to now we have not tried to find the best hyper-parameters for our linear model.\n",
    "Now we are going to find the best subset of features (and therefore the best coefficients) according to RSS or COD evaluated using the validation. \n",
    "In this very simple case we are going to use a brute force approach, we will try every single possible combination of features and evaluate the trained model using the validation dataset.\n",
    "\n",
    "Since our model now depends on the validation dataset we should not use the validation dataset to evaluate the generalization capability of the new model, that is why we need a \"new\" dataset (that we have not used to optimize our model): the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e98b1540dd88d24a028c793aec063c16",
     "grade": false,
     "grade_id": "cell-41b1be06822d4c54",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "\n",
    "# Let's use the functions we built up to now to find the best model order according to the validation criterions.\n",
    "# Once we choose the best model order, which is an hyper-parameter we will estimate its generalization\n",
    "# capability using the test dataset! \n",
    "\n",
    "indexes_subset, train_metrics, val_metrics = [], defaultdict(list), defaultdict(list)\n",
    "for k in range(1, x_train.shape[1] + 1):\n",
    "    print(list(combinations(list(range(x_train.shape[1])), k)))\n",
    "    all_combinations_given_k_choices = list(combinations(list(range(x_train.shape[1])), k))\n",
    "    for indexes in all_combinations_given_k_choices:\n",
    "        indexes_subset.append(indexes)\n",
    "        x_train_subset, x_val_subset = x_train[:, indexes], x_val[:, indexes]\n",
    "        w_hat = compute_LS_optimal_ERM_coefficients(x_train_subset, y_train)\n",
    "        # Predict Training metrics\n",
    "        predictions_train = linear_predictions(w_hat, x_train_subset)\n",
    "        rss_hand_train, cod_hand_train = rss(y_train, predictions_train), cod(y_train, predictions_train)\n",
    "        train_metrics['rss'].append(rss_hand_train)\n",
    "        train_metrics['cod'].append(cod_hand_train)\n",
    "        # Predict Generalization metrics (using the validation set)\n",
    "        predictions_val = linear_predictions(w_hat, x_val_subset)\n",
    "        rss_hand_val, cod_hand_val = rss(y_val, predictions_val), cod(y_val, predictions_val)\n",
    "        val_metrics['rss'].append(rss_hand_val)\n",
    "        val_metrics['cod'].append(cod_hand_val)   \n",
    "\n",
    "# Let's find which is the best model according to the validation error \n",
    "def plot_metric_vs_model_order(indexes_subset, metric_results, ax, plot_info):\n",
    "    for indexes, metric in zip(indexes_subset, metric_results):\n",
    "        ax.scatter(len(indexes), metric, color=plot_info['color'])\n",
    "    # Find best model \n",
    "    best_index = np.argmax(metric_results) if plot_info['metric'] == 'cod' else np.argmin(metric_results)\n",
    "    ax.scatter(len(indexes_subset[best_index]), metric_results[best_index], color=plot_info['color'], marker='x', \n",
    "               s=200, label=f\"Best model according to {plot_info['dataset']}\")\n",
    "\n",
    "    ax.set_xlabel('Model order')\n",
    "    ax.set_ylabel(f\"Metric {plot_info['metric']}\")\n",
    "    ax.set_title(f\"{plot_info['metric']} train vs val for different model orders\")\n",
    "    ax.legend()\n",
    "    return indexes_subset[best_index]\n",
    "    \n",
    "fig, axes = plt.subplots(1,2, figsize=(10, 5))\n",
    "# RSS metric\n",
    "best_features_subset_train = plot_metric_vs_model_order(indexes_subset, train_metrics['rss'], axes[0], \n",
    "                           {'color': 'blue', 'dataset': 'train', 'metric': 'rss'})\n",
    "best_features_subset_val = plot_metric_vs_model_order(indexes_subset, val_metrics['rss'], axes[0], \n",
    "                           {'color': 'red', 'dataset': 'val', 'metric': 'rss'})\n",
    "print(f'Best subset of features according to training: {best_features_subset_train}')\n",
    "print(f'Best subset of features according to validation: {best_features_subset_val}')\n",
    "# COD metric\n",
    "plot_metric_vs_model_order(indexes_subset, train_metrics['cod'], axes[1], \n",
    "                           {'color': 'blue', 'dataset': 'train', 'metric': 'cod'})\n",
    "plot_metric_vs_model_order(indexes_subset, val_metrics['cod'], axes[1], \n",
    "                           {'color': 'red', 'dataset': 'val', 'metric': 'cod'})\n",
    "\n",
    "# We now evaluate the best model (you can choose if you prefer COD or RSS as criterion) on the test dataset\n",
    "w_hat = compute_LS_optimal_ERM_coefficients(x_train[:, best_features_subset_val], y_train)\n",
    "predictions_test_best = linear_predictions(w_hat, x_test[:,best_features_subset_val])\n",
    "rss_hand_test_best, cod_hand_test_best = rss(y_test, predictions_test_best), cod(y_test, predictions_test_best)\n",
    "print(f\"Test metrics for the best model: rss {rss_hand_test_best:.4f}, cod {cod_hand_test_best:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7b2346a0463b96e024a604fd1ccbb5b7",
     "grade": true,
     "grade_id": "cell-69345a5c50d8c67e",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO 8: Compute the confidence intervals of w_hat for the model with 5 parameteres (Use what you have learned during class)\n",
    "# Model with five parameters\n",
    "w_hat = compute_LS_optimal_ERM_coefficients(x_train, y_train)\n",
    "predictions_test = linear_predictions(w_hat, x_test)\n",
    "rss_hand_test, cod_hand_test = rss(y_test, predictions_test), cod(y_test, predictions_test)\n",
    "print(f\"Test metrics: rss {rss_hand_test:.4f}, cod {cod_hand_test:.4f}\")\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError() # Remove this line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "51fc989f9d148075b04ea2655993ab3a",
     "grade": false,
     "grade_id": "cell-cd1c4c719023182c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**TO DO 9**: Answer in the next cell (you do not need more than 5-7 lines):\n",
    "\n",
    "1-Based on these confidence intervals could you conclude that a parameter is not that useful?\n",
    "\n",
    "2-Compare these results with the one obtained in the previous section where we evaluated the best model order. Do they lead to a similar conclusion? Why? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8c5b547ba7f7652234f7738e38f6159d",
     "grade": true,
     "grade_id": "cell-015fda1491c797b7",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
