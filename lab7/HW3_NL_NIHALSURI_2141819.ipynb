{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\" and remove every line containing the expression: \"raise ...\" (if you leave such a line your code will not run).\n",
    "\n",
    "Do not remove any cell from the notebook you downloaded. You can add any number of cells (and remove them if not more necessary).\n",
    "\n",
    "Do not leave any variable initialized to None.\n",
    "\n",
    "## IMPORTANT: make sure to rerun all the code from the beginning to obtain the results for the final version of your notebook, since this is the way we will do it before evaluating your notebook!!!\n",
    "\n",
    "## Make sure to name your notebook file (.ipynb) correctly:\n",
    "### - HW3_NL_NAMESURNAME_ID (E.g. : HW3_NL_MARIOROSSI_2204567)\n",
    "\n",
    "## Fill in your name, surname and id number (numero matricola) below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"NIHAL SURI\"\n",
    "ID_number = int(\"2141819\")\n",
    "\n",
    "import IPython\n",
    "assert IPython.version_info[0] >= 3, \"Your version of IPython is too old, please update it.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3ff9eaae2f9b2bbc8db537ec711deafa",
     "grade": false,
     "grade_id": "cell-076a38b69f1df826",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## HOMEWORK #3\n",
    "\n",
    "### Non linear models for classification \n",
    "\n",
    "In this notebook we are going to explore the use of SVM and Neural Networks for image classification. We are going to use the famous MNIST dataset, that is a dataset of handwritten digits. We get the data from mldata.org, that is a public repository for machine learning data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9bbaec1fea909334962e7a4c356aeba9",
     "grade": false,
     "grade_id": "cell-4ba73b30a541fdaa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Load the required packages\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "\n",
    "import sklearn\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "np.random.seed(ID_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "71a63b13bc065b9c4b1b3353a137ec65",
     "grade": false,
     "grade_id": "cell-87d195f3039741b3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each image is represented as vector of shape (784,)\n",
      "The image is represented in gray scale levels [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   3.  18.\n",
      "  18.  18. 126. 136. 175.  26. 166. 255. 247. 127.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  30.  36.  94. 154. 170. 253.\n",
      " 253. 253. 253. 253. 225. 172. 253. 242. 195.  64.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.  49. 238. 253. 253. 253. 253. 253.\n",
      " 253. 253. 253. 251.  93.  82.  82.  56.  39.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.  18. 219. 253. 253. 253. 253. 253.\n",
      " 198. 182. 247. 241.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  80. 156. 107. 253. 253. 205.\n",
      "  11.   0.  43. 154.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.  14.   1. 154. 253.  90.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 139. 253. 190.\n",
      "   2.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  11. 190. 253.\n",
      "  70.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  35. 241.\n",
      " 225. 160. 108.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  81.\n",
      " 240. 253. 253. 119.  25.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  45. 186. 253. 253. 150.  27.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.  16.  93. 252. 253. 187.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0. 249. 253. 249.  64.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  46. 130. 183. 253. 253. 207.   2.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  39. 148.\n",
      " 229. 253. 253. 253. 250. 182.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  24. 114. 221. 253.\n",
      " 253. 253. 253. 201.  78.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  23.  66. 213. 253. 253. 253.\n",
      " 253. 198.  81.   2.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  18. 171. 219. 253. 253. 253. 253. 195.\n",
      "  80.   9.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.  55. 172. 226. 253. 253. 253. 253. 244. 133.  11.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0. 136. 253. 253. 253. 212. 135. 132.  16.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "Here it is a label: 5\n"
     ]
    }
   ],
   "source": [
    "#load the MNIST dataset \n",
    "#Load data from https://www.openml.org/d/554\n",
    "X,Y = fetch_openml('mnist_784', version=1, return_X_y=True,as_frame = False)\n",
    "\n",
    "print(f'Each image is represented as vector of shape {X[0].shape}')\n",
    "print(f'The image is represented in gray scale levels {X[0]}')\n",
    "print(f'Here it is a label: {Y[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "646f81908715c55f5d5c566087ab9904",
     "grade": false,
     "grade_id": "cell-8f5da37aaf5a57e9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Let's normalize the features so that each value is between [0,1]\n",
    "# Rescale the data\n",
    "X = X / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "141a09fab5765f725c599c3565c9adaf",
     "grade": false,
     "grade_id": "cell-81c18ee97323d3e5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In a classification problem it is desirable to split the dataset into train and test sets in a way that preserves the same proportions of examples in each class as observed in the original dataset.\n",
    "We can achieve this by setting the “stratify” argument of the function \"train_test_split\" to the Y component of our dataset.\n",
    "\n",
    "We are going to use 500 samples in the train dataset, the remaining ones are used for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4342207e6981b614b909b22e8a882fa6",
     "grade": false,
     "grade_id": "cell-e27bcaacee1db729",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length train dataset: 500, Labels and frequencies: \n",
      " [('0', 49), ('1', 56), ('2', 50), ('3', 51), ('4', 49), ('5', 45), ('6', 49), ('7', 52), ('8', 49), ('9', 50)]\n",
      "Length test dataset: 69500, Labels and frequencies: \n",
      " [('0', 6854), ('1', 7821), ('2', 6940), ('3', 7090), ('4', 6775), ('5', 6268), ('6', 6827), ('7', 7241), ('8', 6776), ('9', 6908)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "m_t = 500\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, train_size=m_t/len(Y), random_state=ID_number, stratify=Y)\n",
    "\n",
    "print(f'Length train dataset: {len(y_train)}, Labels and frequencies: \\n {list(zip(*np.unique(y_train, return_counts=True)))}')\n",
    "print(f'Length test dataset: {len(y_test)}, Labels and frequencies: \\n {list(zip(*np.unique(y_test, return_counts=True)))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ec4e86575dfd086d9425c46764d73d13",
     "grade": false,
     "grade_id": "cell-c3f9a9f2f617be66",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Function to plot a digit and print the corresponding label\n",
    "def plot_digit(X_matrix, labels, index):\n",
    "    print(\"INPUT:\")\n",
    "    plt.imshow(\n",
    "        X_matrix[index].reshape(28, 28),\n",
    "        cmap          = plt.cm.gray_r,\n",
    "        interpolation = \"nearest\"\n",
    "    )\n",
    "    plt.show()\n",
    "    print(f\"LABEL: {labels[index]}\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f931c5ab0576c91a41e6ab50bd31881d",
     "grade": false,
     "grade_id": "cell-b2638b70d6ee2365",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 6\n",
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAbXElEQVR4nO3de2zV9f3H8dcp0gNCe1it7WlHYQUVVKBuDLr+UIajo3QL4ZYFL3+AMTBdIcPqdF0URE2qmCjRdLAlG52LqHMRULKxYLUlupYFlBB26WhXBwZalKznlAKF0c/vD+KZB8rleziHd8/h+UhOQs857563X0/65NDTb33OOScAAK6wNOsFAABXJwIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMXGO9wNl6e3t18OBBZWRkyOfzWa8DAPDIOaeuri7l5+crLe38r3P6XYAOHjyogoIC6zUAAJfpwIEDGj58+Hlv73cBysjIkHRm8czMTONtAABehcNhFRQURL6en0/CAlRTU6Pnn39e7e3tKioq0ssvv6zJkydfdO6Lf3bLzMwkQACQxC72bZSEvAnhjTfeUGVlpVauXKmPPvpIRUVFKisr0+HDhxPxcACAJJSQAL3wwgtavHix7rvvPt1yyy1at26drr32Wv36179OxMMBAJJQ3AN08uRJ7dq1S6Wlpf97kLQ0lZaWqrGx8Zz79/T0KBwOR10AAKkv7gH6/PPPdfr0aeXm5kZdn5ubq/b29nPuX11drUAgELnwDjgAuDqY/yBqVVWVQqFQ5HLgwAHrlQAAV0Dc3wWXnZ2tAQMGqKOjI+r6jo4OBYPBc+7v9/vl9/vjvQYAoJ+L+yug9PR0TZw4UXV1dZHrent7VVdXp5KSkng/HAAgSSXk54AqKyu1cOFCffOb39TkyZO1Zs0adXd367777kvEwwEAklBCArRgwQJ99tlnWrFihdrb23Xbbbdp69at57wxAQBw9fI555z1El8WDocVCAQUCoU4EwIAJKFL/Tpu/i44AMDViQABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmIh7gJ588kn5fL6oy9ixY+P9MACAJHdNIj7prbfeqnffffd/D3JNQh4GAJDEElKGa665RsFgMBGfGgCQIhLyPaB9+/YpPz9fo0aN0r333qv9+/ef9749PT0Kh8NRFwBA6ot7gIqLi1VbW6utW7dq7dq1amtr0x133KGurq4+719dXa1AIBC5FBQUxHslAEA/5HPOuUQ+QGdnp0aOHKkXXnhB999//zm39/T0qKenJ/JxOBxWQUGBQqGQMjMzE7kaACABwuGwAoHARb+OJ/zdAcOGDdNNN92klpaWPm/3+/3y+/2JXgMA0M8k/OeAjh49qtbWVuXl5SX6oQAASSTuAXrkkUfU0NCgTz75RH/+8581d+5cDRgwQHfffXe8HwoAkMTi/k9wn376qe6++24dOXJE119/vW6//XY1NTXp+uuvj/dDAQCSWNwD9Prrr8f7UwIAUhDnggMAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATCT8F9IBFo4dOxbT3OrVqz3PtLW1eZ6J5fdj/fOf//Q8E6vZs2d7nmlqavI809HR4Xlm586dnmeef/55zzOS9IMf/MDzTFoaf6+/VBwpAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmOBs2Oj3Ojs7Pc+sX78+psdatWpVTHOpZuPGjdYrnFd2drbnmT/+8Y8xPVZ5ebnnmczMzJge62rEKyAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQnI8UVtWfPHs8z3/3udz3PHD582POMJA0cONDzTFlZmeeZW265xfPM1q1bPc/cfPPNnmek2I7D//3f/3meue222zzPTJgwwfPMkCFDPM8g8XgFBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCY8DnnnPUSXxYOhxUIBBQKhZSZmWm9zlXh2LFjMc2tW7fO88wzzzzjeeY///mP55m5c+d6npGk6upqzzNjxoyJ6bGAVHWpX8d5BQQAMEGAAAAmPAdo+/btmjVrlvLz8+Xz+bRp06ao251zWrFihfLy8jR48GCVlpZq37598doXAJAiPAeou7tbRUVFqqmp6fP21atX66WXXtK6deu0Y8cODRkyRGVlZTpx4sRlLwsASB2efyNqeXm5ysvL+7zNOac1a9bo8ccf1+zZsyVJr7zyinJzc7Vp0ybdddddl7ctACBlxPV7QG1tbWpvb1dpaWnkukAgoOLiYjU2NvY509PTo3A4HHUBAKS+uAaovb1dkpSbmxt1fW5ubuS2s1VXVysQCEQuBQUF8VwJANBPmb8LrqqqSqFQKHI5cOCA9UoAgCsgrgEKBoOSpI6OjqjrOzo6Iredze/3KzMzM+oCAEh9cQ1QYWGhgsGg6urqIteFw2Ht2LFDJSUl8XwoAECS8/wuuKNHj6qlpSXycVtbm3bv3q2srCyNGDFCy5cv1zPPPKMbb7xRhYWFeuKJJ5Sfn685c+bEc28AQJLzHKCdO3fqzjvvjHxcWVkpSVq4cKFqa2v16KOPqru7W0uWLFFnZ6duv/12bd26VYMGDYrf1gCApMfJSFPM8ePHPc/cc889MT3W2WfBSJQFCxZ4nnn88cdjeqxx48bFNAfgfzgZKQCgXyNAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJz7+OAVdOKBTyPPPDH/7Q88yVOqu1pPP+ZtwLieWs6LH+N73//vueZ9ra2jzPPPXUU55nhg4d6nkG6M94BQQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmPA555z1El8WDocVCAQUCoViOgllKnn77bc9z8yePTsBm/TN5/N5nulnT7dzpKV5/ztZb2+v5xm/3+955qc//annmenTp3uekaQpU6Z4nonl2CE1XerXcZ4xAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJTkbaj33yySeeZ5qamjzP/Pe///U8I0ljxozxPNPe3h7TY3l18ODBmOa+//3ve5558cUXPc/89re/9Tzz2WefeZ6J1fr16z3P3HvvvZ5nBg4c6HkG/R8nIwUA9GsECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAlORgoY+Ne//uV55pe//KXnmV/84heeZySps7PT88wf/vAHzzPl5eWeZ9D/cTJSAEC/RoAAACY8B2j79u2aNWuW8vPz5fP5tGnTpqjbFy1aJJ/PF3WZOXNmvPYFAKQIzwHq7u5WUVGRampqznufmTNn6tChQ5HLa6+9dllLAgBSzzVeB8rLyy/6jUO/369gMBjzUgCA1JeQ7wHV19crJydHY8aM0YMPPqgjR46c9749PT0Kh8NRFwBA6ot7gGbOnKlXXnlFdXV1eu6559TQ0KDy8nKdPn26z/tXV1crEAhELgUFBfFeCQDQD3n+J7iLueuuuyJ/Hj9+vCZMmKDRo0ervr5e06dPP+f+VVVVqqysjHwcDoeJEABcBRL+NuxRo0YpOztbLS0tfd7u9/uVmZkZdQEApL6EB+jTTz/VkSNHlJeXl+iHAgAkEc//BHf06NGoVzNtbW3avXu3srKylJWVpVWrVmn+/PkKBoNqbW3Vo48+qhtuuEFlZWVxXRwAkNw8B2jnzp268847Ix9/8f2bhQsXau3atdqzZ49+85vfqLOzU/n5+ZoxY4aefvpp+f3++G0NAEh6ngM0bdo0Xej8pX/6058uayHgajBq1CjPM88++6znmeHDh3uekaRly5Z5nmlubvY8w8lIr26cCw4AYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmfO5Cp7Y2EA6HFQgEFAqF+O2ogJFYzlL917/+9YrMZGRkeJ7BlXWpX8d5BQQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmLjGegEA/c/TTz/teWbSpEmeZ5577jnPM88884znGfRPvAICAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAExwMlIA55g4caLnmdLSUs8zH374oecZpA5eAQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJjgZKYBz+Hw+zzOFhYWeZ7Zt2+Z5BqmDV0AAABMECABgwlOAqqurNWnSJGVkZCgnJ0dz5sxRc3Nz1H1OnDihiooKXXfddRo6dKjmz5+vjo6OuC4NAEh+ngLU0NCgiooKNTU1adu2bTp16pRmzJih7u7uyH0eeughvfPOO3rzzTfV0NCggwcPat68eXFfHACQ3Dy9CWHr1q1RH9fW1ionJ0e7du3S1KlTFQqF9Ktf/UobNmzQd77zHUnS+vXrdfPNN6upqUnf+ta34rc5ACCpXdb3gEKhkCQpKytLkrRr1y6dOnUq6lfzjh07ViNGjFBjY2Ofn6Onp0fhcDjqAgBIfTEHqLe3V8uXL9eUKVM0btw4SVJ7e7vS09M1bNiwqPvm5uaqvb29z89TXV2tQCAQuRQUFMS6EgAgicQcoIqKCu3du1evv/76ZS1QVVWlUCgUuRw4cOCyPh8AIDnE9IOoS5cu1ZYtW7R9+3YNHz48cn0wGNTJkyfV2dkZ9Sqoo6NDwWCwz8/l9/vl9/tjWQMAkMQ8vQJyzmnp0qXauHGj3nvvvXN+8nnixIkaOHCg6urqItc1Nzdr//79Kikpic/GAICU4OkVUEVFhTZs2KDNmzcrIyMj8n2dQCCgwYMHKxAI6P7771dlZaWysrKUmZmpZcuWqaSkhHfAAQCieArQ2rVrJUnTpk2Lun79+vVatGiRJOnFF19UWlqa5s+fr56eHpWVlennP/95XJYFAKQOTwFyzl30PoMGDVJNTY1qampiXgpA8snOzvY8M2XKlARsgmTBueAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgIqbfiAogtfX29nqeaWxs9Dzz9a9/3fMMUgevgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAE5yMFMA5PvvsM88zH3zwgeeZFStWeJ5B6uAVEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABggpORAins7bffjmlu1apVnmdGjx7teebOO+/0PIPUwSsgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEJyMFDGzZssXzzCuvvOJ55ve//73nGUnKzc31PLNmzZqYHgtXL14BAQBMECAAgAlPAaqurtakSZOUkZGhnJwczZkzR83NzVH3mTZtmnw+X9TlgQceiOvSAIDk5ylADQ0NqqioUFNTk7Zt26ZTp05pxowZ6u7ujrrf4sWLdejQochl9erVcV0aAJD8PL0JYevWrVEf19bWKicnR7t27dLUqVMj11977bUKBoPx2RAAkJIu63tAoVBIkpSVlRV1/auvvqrs7GyNGzdOVVVVOnbs2Hk/R09Pj8LhcNQFAJD6Yn4bdm9vr5YvX64pU6Zo3LhxkevvuecejRw5Uvn5+dqzZ48ee+wxNTc366233urz81RXV8f0++cBAMkt5gBVVFRo7969+uCDD6KuX7JkSeTP48ePV15enqZPn67W1laNHj36nM9TVVWlysrKyMfhcFgFBQWxrgUASBIxBWjp0qXasmWLtm/fruHDh1/wvsXFxZKklpaWPgPk9/vl9/tjWQMAkMQ8Bcg5p2XLlmnjxo2qr69XYWHhRWd2794tScrLy4tpQQBAavIUoIqKCm3YsEGbN29WRkaG2tvbJUmBQECDBw9Wa2urNmzYoO9973u67rrrtGfPHj300EOaOnWqJkyYkJD/AABAcvIUoLVr10o688OmX7Z+/XotWrRI6enpevfdd7VmzRp1d3eroKBA8+fP1+OPPx63hQEAqcHzP8FdSEFBgRoaGi5rIQDA1YGzYQNfcqGfWTufpUuXep6pra31PJOdne15JtbTYD388MOeZ/p6kxFwIZyMFABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAw4XMXO8X1FRYOhxUIBBQKhZSZmWm9DgDAo0v9Os4rIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACausV7gbF+cmi4cDhtvAgCIxRdfvy92qtF+F6Curi5JUkFBgfEmAIDL0dXVpUAgcN7b+93ZsHt7e3Xw4EFlZGTI5/NF3RYOh1VQUKADBw5c1WfK5jicwXE4g+NwBsfhjP5wHJxz6urqUn5+vtLSzv+dnn73CigtLU3Dhw+/4H0yMzOv6ifYFzgOZ3AczuA4nMFxOMP6OFzolc8XeBMCAMAEAQIAmEiqAPn9fq1cuVJ+v996FVMchzM4DmdwHM7gOJyRTMeh370JAQBwdUiqV0AAgNRBgAAAJggQAMAEAQIAmEiaANXU1OhrX/uaBg0apOLiYv3lL3+xXumKe/LJJ+Xz+aIuY8eOtV4r4bZv365Zs2YpPz9fPp9PmzZtirrdOacVK1YoLy9PgwcPVmlpqfbt22ezbAJd7DgsWrTonOfHzJkzbZZNkOrqak2aNEkZGRnKycnRnDlz1NzcHHWfEydOqKKiQtddd52GDh2q+fPnq6Ojw2jjxLiU4zBt2rRzng8PPPCA0cZ9S4oAvfHGG6qsrNTKlSv10UcfqaioSGVlZTp8+LD1alfcrbfeqkOHDkUuH3zwgfVKCdfd3a2ioiLV1NT0efvq1av10ksvad26ddqxY4eGDBmisrIynThx4gpvmlgXOw6SNHPmzKjnx2uvvXYFN0y8hoYGVVRUqKmpSdu2bdOpU6c0Y8YMdXd3R+7z0EMP6Z133tGbb76phoYGHTx4UPPmzTPcOv4u5ThI0uLFi6OeD6tXrzba+DxcEpg8ebKrqKiIfHz69GmXn5/vqqurDbe68lauXOmKioqs1zAlyW3cuDHycW9vrwsGg+7555+PXNfZ2en8fr977bXXDDa8Ms4+Ds45t3DhQjd79myTfawcPnzYSXINDQ3OuTP/7wcOHOjefPPNyH3+/ve/O0musbHRas2EO/s4OOfct7/9bffjH//YbqlL0O9fAZ08eVK7du1SaWlp5Lq0tDSVlpaqsbHRcDMb+/btU35+vkaNGqV7771X+/fvt17JVFtbm9rb26OeH4FAQMXFxVfl86O+vl45OTkaM2aMHnzwQR05csR6pYQKhUKSpKysLEnSrl27dOrUqajnw9ixYzVixIiUfj6cfRy+8Oqrryo7O1vjxo1TVVWVjh07ZrHeefW7k5Ge7fPPP9fp06eVm5sbdX1ubq7+8Y9/GG1lo7i4WLW1tRozZowOHTqkVatW6Y477tDevXuVkZFhvZ6J9vZ2Serz+fHFbVeLmTNnat68eSosLFRra6t+9rOfqby8XI2NjRowYID1enHX29ur5cuXa8qUKRo3bpykM8+H9PR0DRs2LOq+qfx86Os4SNI999yjkSNHKj8/X3v27NFjjz2m5uZmvfXWW4bbRuv3AcL/lJeXR/48YcIEFRcXa+TIkfrd736n+++/33Az9Ad33XVX5M/jx4/XhAkTNHr0aNXX12v69OmGmyVGRUWF9u7de1V8H/RCzncclixZEvnz+PHjlZeXp+nTp6u1tVWjR4++0mv2qd//E1x2drYGDBhwzrtYOjo6FAwGjbbqH4YNG6abbrpJLS0t1quY+eI5wPPjXKNGjVJ2dnZKPj+WLl2qLVu26P3334/69S3BYFAnT55UZ2dn1P1T9flwvuPQl+LiYknqV8+Hfh+g9PR0TZw4UXV1dZHrent7VVdXp5KSEsPN7B09elStra3Ky8uzXsVMYWGhgsFg1PMjHA5rx44dV/3z49NPP9WRI0dS6vnhnNPSpUu1ceNGvffeeyosLIy6feLEiRo4cGDU86G5uVn79+9PqefDxY5DX3bv3i1J/ev5YP0uiEvx+uuvO7/f72pra93f/vY3t2TJEjds2DDX3t5uvdoV9fDDD7v6+nrX1tbmPvzwQ1daWuqys7Pd4cOHrVdLqK6uLvfxxx+7jz/+2ElyL7zwgvv444/dv//9b+ecc88++6wbNmyY27x5s9uzZ4+bPXu2KywsdMePHzfePL4udBy6urrcI4884hobG11bW5t799133Te+8Q134403uhMnTlivHjcPPvigCwQCrr6+3h06dChyOXbsWOQ+DzzwgBsxYoR777333M6dO11JSYkrKSkx3Dr+LnYcWlpa3FNPPeV27tzp2tra3ObNm92oUaPc1KlTjTePlhQBcs65l19+2Y0YMcKlp6e7yZMnu6amJuuVrrgFCxa4vLw8l56e7r761a+6BQsWuJaWFuu1Eu799993ks65LFy40Dl35q3YTzzxhMvNzXV+v99Nnz7dNTc32y6dABc6DseOHXMzZsxw119/vRs4cKAbOXKkW7x4ccr9Ja2v/35Jbv369ZH7HD9+3P3oRz9yX/nKV9y1117r5s6d6w4dOmS3dAJc7Djs37/fTZ061WVlZTm/3+9uuOEG95Of/MSFQiHbxc/Cr2MAAJjo998DAgCkJgIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADAxP8Dw8jiEMqoupkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 5\n"
     ]
    }
   ],
   "source": [
    "#let's try the plotting function\n",
    "plot_digit(x_train, y_train, 100)\n",
    "plot_digit(x_test, y_test, 40000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1216eecf5a2a2a9116c547a4bc44e292",
     "grade": false,
     "grade_id": "cell-8173b3832936e560",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## TO DO 1\n",
    "SVM with cross validation to pick the best model. Use SVC from sklearn.svm and GridSearchCV from sklearn.model_selection (5-fold cross-validation).\n",
    "\n",
    "Print the best parameters found as well as the best score obtained by the 'optimal' model.\n",
    "Choose the grid, depending on the kernel you are using different hyper-parameters are needed (C, gamma, ...). \n",
    "You do not need to use more than 5 values for each hyper-parameter (otherwise the cell could be very slow). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8862e281f0b3a2ab802149b59f01fae5",
     "grade": false,
     "grade_id": "cell-a5339e3c792f1d3e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23692\\869788494.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[0mlinear_parameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;31m# YOUR CODE HERE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Remove this line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[0mbest_param_lin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_score_lin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_scores_lin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_best_SVM_with_CV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'linear'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinear_parameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;31m# Choose the grid for parameters of the rbf SVM kernel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# import SVC\n",
    "from sklearn.svm import SVC\n",
    "# import for Cross-Validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "def compute_best_SVM_with_CV(kernel_type : str, parameters : dict, x_train : np.ndarray, y_train : np.ndarray) -> tuple:\n",
    "    '''\n",
    "    Use Cross validation to find the best SVM on the given parameters. Return the best parameters set together with \n",
    "    the corresponding score. Return also the scores for all the other parameters given as input.\n",
    "    :param kernel_type: Type of kernel (i.e. linear, rbf, poly)\n",
    "    :param parameters: Dict containing kernel parameters (e.g. {'C': [1, 10, 100, 1000], 'gamma': [0.01, 0.001], ...})\n",
    "    :param x_train: Train dataset\n",
    "    :param y_train: Train labels\n",
    "    \n",
    "    :returns: (best_param, best_score, all_scores)\n",
    "        WHERE:\n",
    "        best_param: best parameter set (this is a dictionary)\n",
    "        best_score: best score obtained for the given parameters (float)\n",
    "        all_scores: all scores computed for each parameter (np.ndarray)\n",
    "    '''\n",
    "    SVM_model = SVC(kernel=kernel_type)\n",
    "    # Use GridSearchCV to find the best parameter set.\n",
    "    # YOUR CODE HERE\n",
    "    clf = GridSearchCV(SVM_model, parameters)\n",
    "    clf.fit(x_train, y_train)\n",
    "\n",
    "    print('#####################################')\n",
    "    print(f'RESULTS for {kernel_type} KERNEL\\n')\n",
    "    # Store the best parameters set and print them\n",
    "    print(\"Best parameters set found:\")\n",
    "    best_param = clf.best_params_\n",
    "    # YOUR CODE HERE\n",
    "    print(best_param)\n",
    "    \n",
    "    # Store and print the score of the best parameters set\n",
    "    print(\"\\nScore with best parameters:\")\n",
    "    best_score = clf.best_score_\n",
    "    # YOUR CODE HERE\n",
    "    print(best_score)\n",
    "    \n",
    "    # Store and print all the scores for the given parameters (average of the validation scores)\n",
    "    print(\"\\nAll scores on the grid:\")\n",
    "    all_scores = clf.cv_results_\n",
    "    # YOUR CODE HERE\n",
    "    # add code here to the take the mean of the parameters\n",
    "    print(all_scores)\n",
    "    \n",
    "    return best_param, best_score, all_scores\n",
    "\n",
    "# Choose the grid for parameters of the linear SVM kernel\n",
    "linear_parameters = {\n",
    "    'C': [0.1, 1, 10, 100, 1000]\n",
    "}\n",
    "# YOUR CODE HERE\n",
    "\n",
    "best_param_lin, best_score_lin, all_scores_lin = compute_best_SVM_with_CV('linear', linear_parameters, x_train, y_train)\n",
    "# Choose the grid for parameters of the rbf SVM kernel\n",
    "rbf_parameters = {\n",
    "    'C': [0.1, 1, 10, 100, 1000] , \n",
    "    'gamma': [1, 0.1, 0.01, 0.001, 0.0001]\n",
    "}\n",
    "# YOUR CODE HERE\n",
    "\n",
    "best_param_rbf, best_score_rbf, all_scores_rbf = compute_best_SVM_with_CV('rbf', rbf_parameters, x_train, y_train)\n",
    "# Choose the grid for parameters of the poly SVM kernel (do not forget to choose the degree)\n",
    "poly_parameters = {\n",
    "    'C': [0.1, 1, 10, 100, 1000],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "    'degree': [2, 3, 4, 5]\n",
    "}\n",
    "# YOUR CODE HERE\n",
    "\n",
    "best_param_poly, best_score_poly, all_scores_poly = compute_best_SVM_with_CV('poly', poly_parameters, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "207aeacb91c04b8b825a669594ddae01",
     "grade": true,
     "grade_id": "cell-ebaae7b6afc0d0cf",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(best_param_rbf) == dict\n",
    "assert type(best_score_rbf) == np.float64\n",
    "assert np.prod(np.array([len(params) for params in rbf_parameters.values()])) == len(all_scores_rbf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b144521663d002b96ffe699cda280b19",
     "grade": false,
     "grade_id": "cell-afe8e1dfdc2607ec",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO 2: \n",
    "# Get training and test error for the best SVM model obtained from CV (you need to choose across different kernels \n",
    "# too). You just need to look at the best model for each kernel and choose the best one (you can do this by hand).\n",
    "\n",
    "best_kernel_type, best_parameters = None, None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError() # Remove this line\n",
    "best_SVM = SVC(kernel=best_kernel_type, **best_parameters)\n",
    "best_SVM.fit(x_train, y_train)\n",
    "\n",
    "# Compute training and test error for this model (use the usual sklearn built-in functions)\n",
    "training_error, test_error = None, None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError() # Remove this line\n",
    "\n",
    "print (f\"Best SVM training error: {training_error}\")\n",
    "print (f\"Best SVM test error: {test_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "181e1748cf2df2964b15c52e22fadf00",
     "grade": true,
     "grade_id": "cell-4053a73d188e1e77",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(training_error) == np.float64 or float\n",
    "assert type(test_error) == np.float64 or float\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "866343a43003dac21c9eafc823944a39",
     "grade": false,
     "grade_id": "cell-725922e6187a3cca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### TO DO 3\n",
    "Now we use feed-forward neural networks for classification. \n",
    "In particular, we use the Multi-Layer-Perceptron (the multi-layer structure we have seen in class, see http://scikit-learn.org/stable/modules/neural_networks_supervised.html).\n",
    "\n",
    "Similarly as before, we use cross validation (5-fold cross-validation) to pick the best model, you need to complete the function 'compute_best_MLP_with_CV()' that finds the best MLP architecture given a specific activation function.\n",
    "\n",
    "Note that the starting random state is fixed to make the runs reproducible (random_state=ID_number).\n",
    "The following options for the MLP are used: max_iter=1000, alpha=1e-4, solver='sgd', tol=1e-4, random_state=ID_number, learning_rate_init=.1, activation = activation_f. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "473bad63d44a54a6214f207e64471b66",
     "grade": false,
     "grade_id": "cell-c361dd7fdf8988a7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_best_MLP_with_CV(activation_f : str, parameters : dict, x_train : np.ndarray, y_train : np.ndarray) -> tuple:\n",
    "    '''\n",
    "    Use Cross validation to find the best MLP architecture given a specific activation function. \n",
    "    Return the best parameters set together with the corresponding score. Return also the scores for all the other parameters given as input.\n",
    "    :param activation_f: Type of activation function (e.g. 'logistic', 'tanh', 'relu')\n",
    "    :param parameters: architectures (e.g. {'hidden_layer_sizes': [(10,), (50,), (10,10,), (50,50,)]})\n",
    "    :param x_train: Train dataset\n",
    "    :param y_train: Train labels\n",
    "    \n",
    "    :returns: (best_param, best_score, all_scores)\n",
    "        WHERE:\n",
    "        best_param: best parameter set (this is a dictionary)\n",
    "        best_score: best score obtained for the given parameters (float)\n",
    "        all_scores: all scores computed for each parameter (np.ndarray)\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    mlp = MLPClassifier(max_iter=1000, alpha=1e-4, solver='sgd', tol=1e-4, random_state=ID_number, learning_rate_init=.1,activation = activation_f)\n",
    "    \n",
    "    #Use GridSearchCV to find the various paramters the function returns: best_param, best_score, all_scores\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError() # Remove this line\n",
    "    return best_param, best_score, all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0983247a052b55653a2be3c2c69e655d",
     "grade": false,
     "grade_id": "cell-ed0e8862239bb750",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test various architectures (hidden_layer_sizes) and activation functions (e.g. 'logistic','tanh','relu') for the MLP.\n",
    "\n",
    "mlp_parameters = None # leave here maximum 3 architectures when you submit\n",
    "\n",
    "# next test different architectures and activation functions: use compute_best_MLP_with_CV()\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError() # Remove this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "49b7c5c921f59208621a3580b617a100",
     "grade": true,
     "grade_id": "cell-5a81be296062b879",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# simple autotest with relu\n",
    "best_param_relu, best_score_relu, all_scores_relu = compute_best_MLP_with_CV('relu', mlp_parameters, x_train, y_train)\n",
    "\n",
    "assert type(best_param_relu) == dict\n",
    "assert type(best_score_relu) == np.float64 or float\n",
    "assert np.prod(np.array([len(params) for params in mlp_parameters.values()])) == len(all_scores_relu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae813325d9c0f004614b39c912d1f4b5",
     "grade": false,
     "grade_id": "cell-41c31d1b09937db6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Select the best activation function and architecture you found so that it can be used next\n",
    "\n",
    "best_activation_type, mlp_best_param = None, None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError() # Remove this line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "891f23035dcc696a89f5201508b436b0",
     "grade": false,
     "grade_id": "cell-3b3105ef206a32a7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## TO DO 4\n",
    "\n",
    "\n",
    "Now get training and test error for the NN with the best parameters from above. We use verbose=True\n",
    "in input so to see how loss changes in iterations (see how this changes if the number of iterations is changed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f20c5b09c0f6d05abb8a73f4965fa347",
     "grade": false,
     "grade_id": "cell-1bac118c0979b347",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Get training and test error for the best NN model found using CV\n",
    "max_iter = 1000\n",
    "mlp = MLPClassifier(**mlp_best_param, max_iter=max_iter, alpha=1e-4, solver='sgd', tol=1e-4, random_state=ID_number,\n",
    "                    learning_rate_init=.1,activation=best_activation_type, verbose=True)\n",
    "\n",
    "# ADD CODE: FIT MODEL & COMPUTE TRAINING AND TEST ERRORS\n",
    "training_error, test_error = None, None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError() # Remove this line\n",
    "\n",
    "print ('\\nRESULTS FOR BEST NN\\n')\n",
    "\n",
    "print (\"Best NN training error: %f\" % training_error)\n",
    "print (\"Best NN test error: %f\" % test_error)\n",
    "\n",
    "plt.plot(mlp.loss_curve_, label='Training Loss')\n",
    "plt.title('Training loss MLP')\n",
    "plt.xlabel('Iter'), plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "825a634a77cbcad332bb78e86412b58d",
     "grade": true,
     "grade_id": "cell-b01aa80f3128b91d",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(training_error) == np.float64 or float\n",
    "assert type(test_error) == np.float64 or float\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e8c8979eadb59da78e051f520daab77a",
     "grade": false,
     "grade_id": "cell-53fd0895cc28155b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## TO DO  5\n",
    "Write a function to find and plot the first digit (in x_test) that is missclassified by NN and correctly classified by SVM.\n",
    "\n",
    "Write a function to compute the confusion matrix for the predictions of a model (on testset). If you are not familiar with what a confusion matrix is, have a look at this link: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html . You are not allowed to use sklearn to create the confusion matrix BUT you can compare your solution with the sklearn implementation to check you wrote it right (see assert checks). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "faf2def4232c56c7a2066c2a6f315c72",
     "grade": false,
     "grade_id": "cell-6abbf994e14cb54d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def find_and_print_first_mismatched_prediction(SVM_prediction : np.ndarray, NN_prediction : np.ndarray,\n",
    "                                               x_test : np.ndarray, y_test : np.ndarray) -> int:\n",
    "    '''\n",
    "    Function to find and plot (use 'plot_digit') the first digit that is missclassified by NN and correctly classified by SVM.\n",
    "    :param SVM_prediction: SVM predictions.\n",
    "    :param NN_prediction: MLP predictions.\n",
    "    :param x_test: Test set inputs.\n",
    "    :param y_test: Test set labels.\n",
    "    \n",
    "    :returns:\n",
    "        i: returns the first index in which there is a mismatch between NN_prediction and true labels but no mismatch \n",
    "           between SVM_prediction and true labels. \n",
    "    '''\n",
    "    i = 0\n",
    "    found = False\n",
    "    while ((not found) and (i<len(y_test))):\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError() # Remove this line\n",
    "    return i\n",
    "    \n",
    "    \n",
    "def confusion_matrix_by_hand(true_labels : np.ndarray, predicted_labels : np.ndarray) -> np.ndarray:\n",
    "    '''\n",
    "    Function used to compute the confusion matrix given true and predicted labels. \n",
    "    :param true_labels: True labels.\n",
    "    :param predicted_labels: Predicted labels (note this function does not require to know which model generated \n",
    "                             the predictions).\n",
    "    \n",
    "    :returns:\n",
    "        confusion_matrix: Confusion matrix for the given true and predicted labels.\n",
    "    '''\n",
    "    labels = np.unique(true_labels)\n",
    "    map_labels_to_index = {label:i for i, label in enumerate(labels)}\n",
    "    confusion_matrix = np.zeros((len(labels), len(labels)))\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError() # Remove this line\n",
    "    return confusion_matrix.astype(int)\n",
    "\n",
    "# predicted & true labels\n",
    "\n",
    "# Let's test our functions\n",
    "SVM_prediction = best_SVM.predict(x_test)\n",
    "NN_prediction = mlp.predict(x_test)\n",
    "\n",
    "\n",
    "first_index = find_and_print_first_mismatched_prediction(SVM_prediction, NN_prediction, x_test, y_test)\n",
    "\n",
    "SVM_CM = confusion_matrix_by_hand(y_test, SVM_prediction)\n",
    "MLP_CM = confusion_matrix_by_hand(y_test, NN_prediction)\n",
    "\n",
    "print(f'SVM confusion matrix: {SVM_CM}')\n",
    "print(f'MLP confusion matrix: {MLP_CM}')\n",
    "\n",
    "# Convert confusion matrices to pandas data frames\n",
    "labels = np.unique(y_test)\n",
    "SVM_CM_df = pd.DataFrame(SVM_CM, index = labels, columns = labels)\n",
    "MLP_CM_df = pd.DataFrame(MLP_CM, index = labels, columns = labels)\n",
    "\n",
    "# Plot confusion matrices\n",
    "fig, axes = plt.subplots(1,2, figsize=(15,5))\n",
    "sn.heatmap(SVM_CM_df, annot=True, ax=axes[0], cmap='rocket_r', vmax=450)\n",
    "sn.heatmap(MLP_CM_df, annot=True, ax=axes[1], cmap='rocket_r', vmax=450)\n",
    "axes[0].set_title('SVM'), axes[1].set_title('MLP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6f8d07f3967d9a76e811ae04ac8ebdaf",
     "grade": true,
     "grade_id": "cell-6f56cf18ba3807e3",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "skl_confusion_matrix_SVM = confusion_matrix(y_test, SVM_prediction)\n",
    "skl_confusion_matrix_NN = confusion_matrix(y_test, NN_prediction)\n",
    "\n",
    "assert np.sum(skl_confusion_matrix_SVM - SVM_CM) == 0\n",
    "assert np.sum(skl_confusion_matrix_NN - MLP_CM) == 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9d54357ecac3d3a42b963540c4bb3c42",
     "grade": false,
     "grade_id": "cell-e43e0672f19b397b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## TO DO 6: explain the results you got (max 5 lines)\n",
    "According to the cross-validation results, would you choose SVMs or NNs when 500 data points are available for training? Is this a good choice, given the results on the test set?\n",
    "\n",
    "Looking at the confusion matrices, what to do you observe? On which classes each model is more likely to make mistakes? \n",
    "\n",
    "(Answer in the next cell, no need to add code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c9449a004af26a5f1cee1b3e73dd770b",
     "grade": true,
     "grade_id": "cell-2169ccc88e433acd",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c25fbb7d32aa457160151bac43dbc9c0",
     "grade": false,
     "grade_id": "cell-fee6298e8b853f42",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## More Data\n",
    "\n",
    "Now let's do the same but using more data points for training SVM and NN. For SVM we are going to use the best hyperparameters set (kernel, C, gamma, ...) found using 500 data points. For NN we are going to use the best architecture found using 500 data points for the relu kernel since such architecture is usually fast to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "20bfd334c6cb742a5b83cfad08aa7953",
     "grade": false,
     "grade_id": "cell-a848ab7cf8710da9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# let's restart the random generator with the given seed\n",
    "np.random.seed(ID_number)\n",
    "\n",
    "m_t = 60000\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, train_size=m_t/len(Y), random_state=ID_number, stratify=Y)\n",
    "\n",
    "print(f'Lenght train dataset: {len(y_train)}, Labels and frequencies: \\n {list(zip(*np.unique(y_train, return_counts=True)))}')\n",
    "print(f'Lenght test dataset: {len(y_test)}, Labels and frequencies: \\n {list(zip(*np.unique(y_test, return_counts=True)))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d4b6b7529768cedc77543913fab7bb84",
     "grade": false,
     "grade_id": "cell-8749fd4957d4de78",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# As we did with the first HW let's use a decorator to measure time \n",
    "from collections import defaultdict\n",
    "running_times = defaultdict(list)\n",
    "\n",
    "def measure_time(function):\n",
    "    def wrap(*args, **kw):\n",
    "        import time \n",
    "        t_start = time.time()\n",
    "        result = function(*args, **kw)\n",
    "        t_end = time.time()\n",
    "        running_times[type(args[0]).__name__].append(t_end - t_start)\n",
    "        return result\n",
    "    return wrap\n",
    "\n",
    "@measure_time\n",
    "def fit_classification_model(model, x_train, y_train):\n",
    "    model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3f6c7d0fb6ef2afe2e93626ce1ce30b5",
     "grade": false,
     "grade_id": "cell-67568ad39b4b86e3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "n_data = [250, 500, 1000, 2000, 5000, 7500]\n",
    "svm_train_err, svm_test_err = [], [] \n",
    "mlp_train_err, mlp_test_err = [], [] \n",
    "for n in n_data: \n",
    "    print(f'Processing with {n} data ...')\n",
    "    # Initialize models according to the best we got using 500 data\n",
    "    svm = SVC(kernel=best_kernel_type, **best_parameters)\n",
    "    mlp = MLPClassifier(**best_param_relu, max_iter=max_iter, alpha=1e-4, solver='sgd', tol=1e-4, \n",
    "                        random_state=ID_number, learning_rate_init=.1,activation='relu')\n",
    "\n",
    "    # fit svc\n",
    "    fit_classification_model(svm, x_train[:n], y_train[:n])\n",
    "    # get svc train and test error\n",
    "    svm_train_err.append(1. - svm.score(x_train[:n], y_train[:n]))\n",
    "    svm_test_err.append(1. - svm.score(x_test, y_test))\n",
    "    \n",
    "    # fit mlp\n",
    "    fit_classification_model(mlp, x_train[:n], y_train[:n])\n",
    "    # get mlp train and test error\n",
    "    mlp_train_err.append(1. - mlp.score(x_train[:n], y_train[:n]))\n",
    "    mlp_test_err.append(1. - mlp.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "76cdcc33de26eab0389241936928eff6",
     "grade": false,
     "grade_id": "cell-32afc1730a114434",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2, figsize=(15, 5))\n",
    "axes[0].plot(n_data, np.array(svm_train_err), label='SVM train err')\n",
    "axes[0].plot(n_data, np.array(svm_test_err), label='SVM test err')\n",
    "axes[0].plot(n_data, np.array(mlp_train_err), label='MLP train err')\n",
    "axes[0].plot(n_data, np.array(mlp_test_err), label='MLP test err')\n",
    "axes[0].set_xlabel('N data'), axes[0].set_ylabel('Loss')\n",
    "axes[0].legend(), axes[0].set_title('SVC vs MLP Errors')\n",
    "\n",
    "for model, times in running_times.items():\n",
    "    axes[1].plot(n_data, times, label=model)\n",
    "axes[1].set_xlabel('N data'), axes[1].set_ylabel('Time (s)')\n",
    "axes[1].legend(), axes[1].set_title('Training Time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2cdd9b28875b481b1861df52f3f424b0",
     "grade": false,
     "grade_id": "cell-850f1836c9d53145",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# TODO 7: Complete dataset\n",
    "Just for comparison, since it may not be possible to learn a SVM on too many data (due to time and memory complexity issues as you can notice from the plots above), let's use logistic regression (with standard parameters from scikit-learn but the number of iteration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "20e6fd0bc8b37886b5a6f2a6e235b049",
     "grade": false,
     "grade_id": "cell-916c97aa3e1b4655",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "# Fit and test a logistic regression model (same as HW1)\n",
    "max_iter = 1000\n",
    "log_reg = None\n",
    "training_error_lr, test_error_lr = None, None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError() # Remove this line\n",
    "\n",
    "print (f\"Best logistic regression training error: {training_error_lr:.4f}\")\n",
    "print (f\"Best logistic regression test error: {test_error_lr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d0a20eac6a2870207c1ad18062737b01",
     "grade": false,
     "grade_id": "cell-005fbf84d90498d9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We now learn the NN. Below we use the same best architecture as before (found with 500 data for the relu activation function), feel free to try larger ones (and to use again CV), or smaller ones if it takes too much time. (We suggest that you use 'verbose=True' so have an idea of how long it takes to run 1 iteration). \n",
    "\n",
    "*Note*: If you do again CV to choose the best architecture remember to save the best set of parameters into the variable: \"best_param_relu\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3394b96ed31d61a7a31395d7286ecba3",
     "grade": false,
     "grade_id": "cell-21ceb4a0710c5e96",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# get training and test error for the best NN model from CV\n",
    "best_mlp_large = None\n",
    "training_error, test_error = None, None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError() # Remove this line\n",
    "\n",
    "print ('\\nRESULTS FOR BEST NN\\n')\n",
    "\n",
    "print (f\"Best NN training error: {training_error:.4f}\")\n",
    "print (f\"Best NN test error: {test_error:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "607558412cec9ddce399356c9ae65888",
     "grade": true,
     "grade_id": "cell-749912093733565e",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(training_error) == np.float64 or float\n",
    "assert type(test_error) == np.float64 or float\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6407f3bb7a387b0d396892b129988850",
     "grade": false,
     "grade_id": "cell-ef2ebd626161b3c3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## TODO 8: compute the confusion matrices both on train and test set for Logistic regression (trained on 60k)\n",
    "# and MLP (trained on 60k). Use the function 'confusion_matrix_by_hand' that you wrote before\n",
    "\n",
    "# Log Reg Confusion matrices\n",
    "log_reg_CM_train, log_reg_CM_test = None, None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError() # Remove this line\n",
    "\n",
    "# mlp\n",
    "mlp_CM_train, mlp_CM_test = None, None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError() # Remove this line\n",
    "\n",
    "\n",
    "# Convert confusion matrices to pandas data frames\n",
    "labels = np.unique(y_test)\n",
    "log_reg_CM_train_df = pd.DataFrame(log_reg_CM_train, index = labels, columns = labels)\n",
    "log_reg_CM_test_df = pd.DataFrame(log_reg_CM_test, index = labels, columns = labels)\n",
    "\n",
    "mlp_CM_train_df = pd.DataFrame(mlp_CM_train, index = labels, columns = labels)\n",
    "mlp_CM_test_df = pd.DataFrame(mlp_CM_test, index = labels, columns = labels)\n",
    "\n",
    "# Plot confusion matrices\n",
    "fig, axes = plt.subplots(1,2, figsize=(15,5))\n",
    "sn.heatmap(log_reg_CM_train_df, annot=True, ax=axes[0], cmap='rocket_r', vmax=250)\n",
    "sn.heatmap(log_reg_CM_test_df, annot=True, ax=axes[1], cmap='rocket_r', vmax=250)\n",
    "axes[0].set_title('Log Reg Train'), axes[1].set_title('Log Reg Test')\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(15,5))\n",
    "sn.heatmap(mlp_CM_train_df, annot=True, ax=axes[0], cmap='rocket_r', vmax=50)\n",
    "sn.heatmap(mlp_CM_test_df, annot=True, ax=axes[1], cmap='rocket_r', vmax=50)\n",
    "axes[0].set_title('MLP Train'), axes[1].set_title('MLP Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "56f669c88be1984b1e67a92933699740",
     "grade": true,
     "grade_id": "cell-20e1f551d47d4809",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert log_reg_CM_train.shape == (10, 10)\n",
    "assert log_reg_CM_test.shape == (10, 10)\n",
    "assert mlp_CM_train.shape == (10, 10)\n",
    "assert mlp_CM_test.shape == (10, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "48bf45da3556dcf5373ab56ca5172459",
     "grade": false,
     "grade_id": "cell-bb8ab6d807b36a9e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## TO DO 9\n",
    "Compare and discuss:\n",
    "- the computational time required to fit a SVM and a MLP. Which is faster as the number of data increase? Why? Can you apply both methods in the high data regime?\n",
    "- the results from SVM m=7500 and NN with m=60000 training data points.\n",
    "- the results from NN with m=500 and m=60000 training data points.\n",
    "- What do you observe in the confusion matrices? Which are the hardest classes? Are the hardest and easiest classes the same both for mlp and logistic regression?\n",
    "\n",
    "(Answer in the next cell, no need to write code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ac9506d7b0d0287fab6d1500ddf854a6",
     "grade": true,
     "grade_id": "cell-fd40eed840f9e7a0",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "253795ed7dd59141236859ea6fc24938",
     "grade": false,
     "grade_id": "cell-b6b8757aa45ac7db",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Data normalization\n",
    "\n",
    "In the following the importance of data normalization is investigated. In particular, a MLP with a (50,50,) architecture and a 'logistic' activation function is trained with the original MNIST data and the effects are analized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "093f82ebff395f0668df235da0472fba",
     "grade": false,
     "grade_id": "cell-51b11e60a9629efe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# data are restored to their original scale \n",
    "X = X*255.\n",
    "print(X[1])\n",
    "\n",
    "# train-test data split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, train_size=m_t/len(Y), random_state=ID_number, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e9e5b7bef253337edf9b437a21ffd0ee",
     "grade": false,
     "grade_id": "cell-2f35cc1412a6b8ef",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "best_mlp_large = MLPClassifier(hidden_layer_sizes=(50,50,), max_iter=max_iter, alpha=1e-4,activation='logistic', solver='sgd', tol=1e-4, \n",
    "                               random_state=None, learning_rate_init=.1, verbose=True)\n",
    "best_mlp_large.fit(x_train, y_train)\n",
    "training_error = 1. - best_mlp_large.score(x_train, y_train)\n",
    "test_error = 1. - best_mlp_large.score(x_test, y_test)\n",
    "\n",
    "\n",
    "print ('\\nRESULTS FOR BEST NN\\n')\n",
    "\n",
    "print (f\"Best NN training error: {training_error:.4f}\")\n",
    "print (f\"Best NN test error: {test_error:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e48d0569c46960a9e5dfccb5adbc3144",
     "grade": false,
     "grade_id": "cell-07de839aff93fd1f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## TO DO 10\n",
    "\n",
    "Do you think data normalization is important? Why? Do you observe any difference between the results you obtained before and after scaling the data?\n",
    "\n",
    "(Answer in the next cell, no need to write code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4f3e75bb607e358ca7693ac27cea0130",
     "grade": true,
     "grade_id": "cell-eb534567f623d0dc",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3a07e62e4a7a0b75da90707a1a71cb95",
     "grade": false,
     "grade_id": "cell-8342d0b7141d9fe6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## BONUS CONTENT (READ-ONLY)\n",
    "The Homework is finished at this point, the following cells are read-only and optional.\n",
    "\n",
    "Here you will see how Neural Networks (in this case Convolutional NNs) are actually implemented in practice. We will exploit the PyTorch library (see the docs here: https://pytorch.org/docs/stable/index.html) to implement a CNN to solve the same classification problem in the MNIST dataset that you have faced so far. Note that this is not the best possible implementation and it is also a sort of overkill for this particular problem. Nonetheless, understanding the following code can still be useful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "03eab3e440581e25d2b4ecb8ffea7b4f",
     "grade": false,
     "grade_id": "cell-52a92fab9be6a9f1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7527a420d4841af2aacf0e5a259df1b7",
     "grade": false,
     "grade_id": "cell-3db3b53494b62a36",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Import PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Re-download, preprocess and split the dataset\n",
    "X,Y = fetch_openml('mnist_784', version=1, return_X_y=True,as_frame = False)\n",
    "X = (X / 255. - 0.5) / 0.5\n",
    "m_t = 60000\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, train_size=m_t/len(Y), random_state=ID_number, stratify=Y)\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "x_train = torch.tensor(x_train.astype(np.float32)).unsqueeze(dim=-1).unsqueeze(dim=-1).view(-1, 1, 28, 28)\n",
    "x_test = torch.tensor(x_test.astype(np.float32)).unsqueeze(dim=-1).unsqueeze(dim=-1).view(-1, 1, 28, 28)\n",
    "\n",
    "y_train = torch.tensor(y_train.astype(int))\n",
    "y_test = torch.tensor(y_test.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2c6c85fb57b7f6fa6e0f808729de7a41",
     "grade": false,
     "grade_id": "cell-74b108055a204077",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Define the Convolutional Neural Network layer by layer and implement the forward pass\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64 * 5 * 5, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Check if we can run our experiment on a GPU (much faster)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = CNN().to(device)\n",
    "\n",
    "# Define the loss function and the optimizer (Adam docs: https://pytorch.org/docs/stable/generated/torch.optim.Adam.html)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "n_epochs = 10000\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    indexes = np.random.randint(0, high=x_train.shape[0], size=64)\n",
    "    x_batch = x_train[indexes].to(device)\n",
    "    y_batch = y_train[indexes].to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs = model(x_batch)\n",
    "    loss = criterion(outputs, y_batch)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    running_loss = loss.item()\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"Epoch {epoch}/{n_epochs}, Loss: {running_loss:.4f}\")\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "outputs = model(x_test.to(device))\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "total = y_test.shape[0]\n",
    "correct = (predicted == y_test).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
